{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cog_Sci_Exam_Start",
      "provenance": [],
      "collapsed_sections": [
        "H7qJOY7lMyXj",
        "OPfLpwau5D3g",
        "SubOrCUA4hV1",
        "K7Mz9Isn6C6u",
        "CSlS2CiOLwJ1"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXalb38fhwgD",
        "colab_type": "code",
        "outputId": "47317595-323a-48f7-c742-431e50140279",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
        "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
        "from sklearn.feature_selection import SelectKBest, chi2, f_regression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Libraries for loading data\n",
        "import h5py\n",
        "import pathlib\n",
        "\n",
        "# Text proccessing\n",
        "import re\n",
        "import nltk  \n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHCHF_tO8HQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_text, X_audio, y data is not algined\n",
        "movies_indices = ['100178', '100232', '100367', '100446', '100499', '100961', '10124', '101513', '101635', '101708', '101787', '101851', '101880', '102168', '102184', '10219', '102213', '10223', '102389', '102408', '102424', '102534', '102858', '103114', '103311', '10397', '104739', '104741', '105507', '105537', '105553', '105906', '105963', '106037', '106077', '106514', '106941', '106973', '107182', '107456', '107551', '107585', '108146', '108793', '109524', '109909', '110003', '110203', '110543', '110565', '110690', '110754', '110766', '110788', '110794', '110824', '110983', '111104', '111363', '111734', '111881', '112029', '112148', '112169', '112172', '112223', '112425', '112433', '112509', '112604', '112631', '112674', '112903', '113162', '113265', '113369', '113491', '114006', '114016', '114419', '114624', '114845', '115134', '116202', '116213', '116219', '116221', '116461', '116481', '11650', '118354', '118371', '118573', '118583', '118639', '119348', '119397', '120342', '120363', '121117', '121128', '121358', '121400', '121427', '121584', '121759', '122439', '122581', '122602', '122842', '123986', '124190', '125344', '125676', '125708', '125726', '125730', '125845', '125868', '125895', '126505', '126542', '126831', '126872', '127470', '127490', '127539', '127622', '127908', '128059', '12812', '128258', '128600', '128752', '128763', '128949', '129728', '129733', '130149', '130366', '130426', '130448', '130456', '130633', '131650', '131871', '131936', '132028', '132476', '132570', '133201', '133888', '134252', '134298', '135623', '135658', '136196', '136205', '136211', '136215', '136234', '136416', '136647', '137455', '137827', '137920', '139006', '139032', '140293', '140315', '140317', '15138', '154449', '15837', '16145', '16530', '167521', '172044', '172048', '172050', '172060', '17622', '176266', '17769', '178163', '17874', '179797', '179875', '180923', '180971', '181504', '181978', '183364', '184784', '186631', '186643', '187033', '187566', '187775', '188004', '188062', '188122', '188343', '188815', '188825', '18938', '189966', '190599', '190726', '190740', '190743', '191616', '191941', '192799', '192978', '193093', '193291', '193322', '193514', '193894', '193921', '193924', '194299', '194625', '195575', '19573', '19664', '196665', '197232', '197778', '198112', '19850', '19915', '199215', '199227', '200941', '201005', '201497', '201582', '201980', '202431', '202810', '202826', '202990', '203466', '203806', '204085', '204378', '204519', '204792', '205268', '206049', '206051', '206148', '206179', '206376', '206507', '206585', '206606', '206621', '207118', '207812', '207867', '207958', '207964', '207977', '208148', '208299', '208322', '208416', '208465', '208592', '209354', '209758', '209775', '209869', '210098', '210238', '210240', '210259', '210433', '210555', '210618', '21137', '211611', '211875', '212532', '21285', '213207', '213327', '213619', '214095', '215259', '215318', '215343', '216007', '216030', '216097', '21638', '216831', '216857', '21696', '21727', '21735', '217395', '21844', '218708', '218757', '218912', '219310', '219350', '219460', '219600', '219605', '219614', '219775', '220134', '220200', '220548', '220809', '221104', '221137', '221153', '221274', '221740', '222116', '222247', '222510', '222605', '22277', '22305', '223333', '223338', '22335', '223377', '223431', '22344', '22360', '22373', '223883', '223885', '223926', '224263', '224292', '224325', '224370', '224472', '224498', '224599', '224622', '224631', '224648', '224649', '224772', '224817', '224869', '225343', '225416', '225768', '225770', '22649', '226601', '226602', '226640', '22689', '227173', '22719', '227416', '227426', '227556', '22785', '22798', '22821', '228561', '22880', '228925', '22901', '229090', '229296', '229808', '229903', '229967', '230252', '230422', '230692', '231025', '231412', '231453', '232464', '23289', '233171', '233356', '233366', '233389', '23343', '233880', '233939', '234046', '234053', '234406', '234587', '234641', '236021', '236306', '236399', '236442', '23656', '236696', '237009', '237363', '238023', '238039', '238060', '238063', '238100', '238567', '238624', '238645', '238683', '238858', '238889', '239180', '239235', '239242', '239572', '240915', '241124', '241164', '241172', '241178', '24157', '241629', '241638', '24196', '24202', '243056', '243338', '243341', '24351', '243646', '243797', '243981', '244180', '244261', '244623', '244817', '244829', '244836', '24504', '24508', '245207', '245243', '245276', '245322', '245497', '245582', '245926', '24602', '246216', '247108', '247318', '247382', '247538', '247764', '248024', '24814', '248400', '248837', '250430', '251417', '251646', '251826', '251839', '252097', '252177', '25271', '252912', '252919', '252998', '253709', '254298', '254427', '255205', '25522', '255224', '255226', '255338', '255343', '255408', '255852', '256174', '25640', '256935', '256976', '257045', '257247', '257277', '257531', '257534', '257771', '258654', '258672', '258802', '259260', '259470', '260011', '260199', '26110', '26113', '26115', '261267', '261326', '261900', '261902', '262165', '262226', '262341', '263444', '263889', '264418', '264446', '265302', '265811', '265959', '266366', '266396', '266791', '266852', '266861', '26690', '266938', '267092', '267252', '267255', '267278', '267354', '267466', '267694', '267799', '26808', '268258', '268536', '268836', '270254', '270416', '270439', '270444', '270449', '270628', '270665', '270956', '270993', '271366', '271594', '271598', '272375', '272624', '272817', '272838', '273032', '273171', '273207', '273237', '273250', '273314', '273510', '273531', '273539', '274073', '274185', '274219', '274917', '275248', '275267', '275603', '275620', '276217', '27798', '277991', '278474', '27857', '27863', '279373', '28006', '280584', '280794', '280951', '28142', '28182', '28191', '282560', '282586', '282985', '283495', '283935', '284673', '286943', '288714', '288766', '290062', '290088', '29044', '290546', '291121', '292277', '294178', '294226', '295793', '29751', '29758', '29771', '298459', '298736', '298774', '29920', '299754', '301320', '301321', '30162', '30171', '302220', '30646', '306700', '30762', '30763', '30858', '31197', '31392', '31474', '31544', '323217', '32459', '32681', '327282', '327283', '33089', '33170', '33272', '33312', '33436', '33439', '341382', '341763', '341983', '342197', '342407', '34346', '34640', '34684', '34984', '34989', '35684', '35694', '35934', '36098', '36116', '36164', '367506', '367576', '368460', '370050', '370404', '37117', '37459', '38019', '38154', '38374', '38387', '40129', '40181', '40247', '40260', '40266', '40970', '41026', '41032', '41381', '41692', '42426', '42946', '43342', '43371', '43444', '43456', '43469', '44457', '44780', '45175', '45184', '45186', '45676', '45860', '46495', '46497', '46503', '46604', '46615', '46618', '46663', '46860', '47472', '47797', '47939', '48019', '48300', '48724', '49029', '49073', '49264', '49358', '49417', '49903', '50103', '50302', '50306', '50307', '50444', '50453', '50478', '50479', '51224', '52067', '52068', '52160', '52839', '535523', '53609', '53742', '53766', '55156', '56006', '56276', '56853', '56989', '57231', '57294', '57295', '57598', '57618', '58096', '58097', '58151', '58554', '58795', '59302', '59333', '59673', '59712', '60037', '60405', '60428', '61277', '61531', '61557', '62438', '63841', '63951', '63956', '65068', '65939', '66505', '66623', '68828', '69234', '69268', '69707', '69824', '69870', '70280', '70299', '70420', '70710', '71459', '7155', '7156', '71736', '71987', '72017', '72385', '73360', '73447', '73449', '74101', '74184', '74447', '74532', '74870', '75393', '75441', '75892', '75938', '76104', '76124', '78398', '78577', '78752', '79203', '79356', '79644', '79858', '79925', '79934', '79935', '80566', '80620', '80627', '80855', '80866', '80914', '81371', '81406', '81538', '81563', '81615', '81668', '81707', '82666', '83119', '83310', '83400', '83859', '8404', '84133', '84140', '84176', '84670', '84772', '84924', '86494', '87161', '87163', '87400', '87434', '88077', '88119', '88245', '88791', '88792', '88797', '88881', '88888', '89184', '89266', '89747', '89787', '89835', '89951', '90008', '90172', '90396', '90667', '90986', '91166', '91276', '91292', '91574', '91844', '91996', '92221', '92291', '92331', '92496', '92521', '92533', '92578', '93116', '93119', '93807', '93821', '93828', '93839', '93843', '94215', '94439', '94481', '94525', '94532', '94983', '95147', '95205', '95388', '95887', '96099', '96179', '96194', '96337', '96350', '96361', '96642', '96694', '96700', '97076', '97095', '97289', '97908', '97992', '98155', '98187', '98442', '98505', '98562', '99331', '99501']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUo52Ks4bZsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # This is how data comes in\n",
        "# y_file = {'100178': [....], '100232': [....], '100367': [....]}\n",
        "# X_text_file = {'100232': [....], '100178': [....], '100367': [....]}\n",
        "# X_audio_file = {'100367': [....], '100232': [....], '100178': [....]}\n",
        "\n",
        "# # This is how we proccess it\n",
        "# y = []\n",
        "# for i in movies_indices:\n",
        "#   y.append(y_file[i])\n",
        "#   X_text.append(X_text_file[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9NsXYLjvr2K",
        "colab_type": "text"
      },
      "source": [
        "# Text Download\n",
        "We download pre-proccessed data from CMU-Multimodal-SDK."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYjCYK9Dh9uc",
        "colab_type": "code",
        "outputId": "2dfbdeb7-63fa-4005-84e0-0589a14619e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "data_root = '.'\n",
        "tf.keras.utils.get_file('y_pers', 'http://immortal.multicomp.cs.cmu.edu/POM/labels/POM_Labels_Video_Level_Persuasion.csd', cache_dir=data_root)\n",
        "# tf.keras.utils.get_file('y_sentiment', 'http://immortal.multicomp.cs.cmu.edu/POM/labels/POM_Labels_Video_Level_Sentiment.csd', cache_dir=data_root)\n",
        "# tf.keras.utils.get_file('y_traits', 'http://immortal.multicomp.cs.cmu.edu/POM/labels/POM_Labels_Video_Level_Personality_Traits.csd', cache_dir=data_root)\n",
        "tf.keras.utils.get_file('X_words', 'http://immortal.multicomp.cs.cmu.edu/POM/language/POM_TimestampedWords.csd', cache_dir=data_root)\n",
        "tf.keras.utils.get_file('X_word_vecs', 'http://immortal.multicomp.cs.cmu.edu/POM/language/POM_TimestampedWordVectors.csd', cache_dir=data_root)\n",
        "tf.keras.utils.get_file('X_sound', 'http://immortal.multicomp.cs.cmu.edu/POM/acoustic/POM_COVAREP.csd', cache_dir=data_root)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://immortal.multicomp.cs.cmu.edu/POM/language/POM_TimestampedWordVectors.csd\n",
            "768344064/768338264 [==============================] - 171s 0us/step\n",
            "Downloading data from http://immortal.multicomp.cs.cmu.edu/POM/acoustic/POM_COVAREP.csd\n",
            "1756012544/1756011552 [==============================] - 402s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./datasets/X_sound'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdeV0U35vv-V",
        "colab_type": "text"
      },
      "source": [
        "# Text Proccessing\n",
        "1. Extract data from files.\n",
        "2. Concatenate & clean where necessary (Text)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lrAx06rBGUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_data(data_name, file_path, concat_feat=False):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "    data_name: name of the data to be extracted\n",
        "    file_path: path to file\n",
        "    concat_feat: concat words for text data\n",
        "  Returns:\n",
        "    numpy array with the data from the file\n",
        "  \"\"\"\n",
        "  with h5py.File(file_path, 'r') as hf:\n",
        "    data = []\n",
        "    print(hf.keys())\n",
        "    for i in movies_indices:\n",
        "      to_append = hf[data_name]['data'][i]['features'][:]\n",
        "      if (concat_feat):\n",
        "        to_append = np.array2string(np.concatenate(to_append))\n",
        "      data.append(to_append)\n",
        "  return np.array(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWs_w9--qEdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "  \"\"\"\n",
        "  Arguments: \n",
        "    text: text to be parsed\n",
        "  Returns\n",
        "    text without special characters\n",
        "  \"\"\"\n",
        "  text = re.sub(r\"\\n\", \" \", text)\n",
        "  text = re.sub(r\"sp\", \" \", text)\n",
        "  text = text.lower()\n",
        "  text = re.sub(r\"[^a-z ]\", \" \", text) # remove everything expect a-z\n",
        "  text = re.sub(r\"\\b\\w{1,1}\\b\", \" \",text) # remove everything of length 1\n",
        "  text = \" \".join([x for x in text.split()])\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVOxU-M-EPae",
        "colab_type": "code",
        "outputId": "2d0d5870-7a88-4bd5-ac75-8b67b85be7b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "y_pers = extract_data('video level persuasion', './datasets/y_pers').squeeze() # persuasivness labels\n",
        "# y_traits = extract_data('video level personality traits', './datasets/y_traits').squeeze() # personality labels\n",
        "# y_sentiment = extract_data('video level sentiment', './datasets/y_sentiment').squeeze() # sentiment polarity labels\n",
        "X_text = extract_data('words', './datasets/X_words', concat_feat=True) # not clean text\n",
        "X_text = np.vectorize(clean_text)(X_text) # clean text\n",
        "X_word_vecs = extract_data('glove_vectors', './datasets/X_word_vecs') # glove word vectors\n",
        "X_audio = extract_data('COAVAREP', './datasets/X_sound') # COVAREP audio features\n",
        "\n",
        "print(\"X_text shape: {}\".format(X_text.shape))\n",
        "print(\"y_pers: {}\".format(y_pers.shape))\n",
        "# print(\"y_sentiment: {}\".format(y_sentiment.shape))\n",
        "print(\"X_text shape: {}\".format(X_text.shape))\n",
        "print(\"X_audio: {}\".format(X_audio.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<KeysViewHDF5 ['video level persuasion']>\n",
            "<KeysViewHDF5 ['words']>\n",
            "<KeysViewHDF5 ['glove_vectors']>\n",
            "<KeysViewHDF5 ['COAVAREP']>\n",
            "X_text shape: (903,)\n",
            "y_pers: (903,)\n",
            "X_text shape: (903,)\n",
            "X_audio: (903,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdWi8LEdcgaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Binary split\n",
        "# persuasive > 5 & persuasive < 3\n",
        "pers_relevant_i = np.where((y_pers > 5) | (y_pers < 3))\n",
        "X_text_pers = X_text[pers_relevant_i]\n",
        "X_audio_pers = X_audio[pers_relevant_i]\n",
        "\n",
        "y_binary_pers = y_pers[pers_relevant_i]\n",
        "y_binary_pers[y_binary_pers < 3] = 0.0\n",
        "y_binary_pers[y_binary_pers > 5] = 1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUEv-2cadoNj",
        "colab_type": "code",
        "outputId": "33b3115d-54af-4b1b-e332-1df4370f24a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(pers_relevant_i[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEkLI7QnWfnP",
        "colab_type": "code",
        "outputId": "533f1832-4097-40a5-bfe5-25184c18a367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "X_text[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['hi there today we re going to be reviewing cheaper by the dozen which is umm the original version there second movie out now but this is uhh steve martin in the first role it tells the story of umm family with twelve kids and his attempts to raise them umm includes hillary duff bonnie hunt tom welling and piper umm all names that should be familiar with kids and some adults and so this kind of makes the movie have wide appeal didn really like the movie thought it was cheesy think steve done other better things ebert and roper apparently said two thumbs up here on the cover but for me it probably two thumbs down umm the humor seemed kind of contrived kind of you know slapstick uhh the dad getting hit by the kids or someone acting up sort of thing not all that funny and not all that original and didn think the acting was all that great either but who knows umm am probably tougher on movies than lot of people this was pretty popular umm and it good choice for like said kids or families umm so if you re looking for something it sort of lighthearted umm it only cheaper by the dozen is good place to look but for me it only gets two stars out of five thanks',\n",
              "       'hi there today we re going to be reviewing the of gladiator which is uhh big russell crowe film from uhh late nineteen nineties umm it won uhh academy awards and it was quite popular movie umm it tells the story of the gladiator who is played by russell crowe and his attempts sort of to gain freedom for himself and resist umm the emperor at the time umm it really good movie it long uhh that primary complaint against it it over two two stutter and half hours so you need to have some time to sit down and watch gladiator but russell crowe does really good job and he really believable in the role umm and it really thoroughly entertaining from start to finish umm it shot in very stutter cinematic style guess guess all movies can be shot in cinematic style but the photography in this one seemed in particular excellent to me umm and it really was just thought fantastic movie uhh you can the pretty cheap now it shouldn be too expensive it been out uhh for several years but if you haven seen it and you somehow missed it the first time around it really is great story umm to check out definitely not for the kids it an adult movie but umm yeah if you fit in the age group and haven seen gladiator go get it five stars out of five thanks',\n",
              "       'hi everyone today going to do my expo review on this movie called the princess diaries this is the first of two movies umm and it stars julie andrews and anne hathaway this is one of her first movies ve ever seen her in she really young umm and this movie came out little over five years ago loved it it was so cute one of the really good disney movies ve ever seen disney makes good movies umm it on but it also on and you can probably get it for about fifteen dollars maybe ten dollars because it pretty pretty old it not that recent or new but there also sequel to it princess diaries two umm it was okay but this is the better of the two and it about normal girl high school girl that transforms herself into princess because she actually princess because her dad was the king of some little country definitely check it out if you like the old good heart umm good hearted movies by and it called princess diaries thanks',\n",
              "       'hey here have the movie vin diesel in the pacifier this movie is so it awesome it the version of course and uhh as you can see vin diesel you know tries to do all he can in raising the kids and and it just awesome umm he comes in and he uhh he just he just stutter it an adventure he has babysitting job and it so adventurous it by walt disney and it hilarious he tries to change diapers and umm ills all over and he just it just awesome there lot of bonus features it great for the whole family umm and it it stutter vin diesel and he even has his shirt off in one of the scenes and that pretty hot you know umm it rated and uhh was in uhh working at the ho ital the other night and uhh some guy was watching it and he just rolling he loved it and it just cool movie so give it five out of five star rating',\n",
              "       'hey expo umm have you ever seen this movie shaggy dog uhh walt disney uhh it uhh okay this movie umm saw it at the movie theater at the dollar theater luckily because wasn very impressed by it mean you know tim allen is pretty funny in it but the movie itself is so cheesy like it just it just stutter really cheesy and it says it going to be ruff day get it ruff day umm like tim allen turns into this shaggy dog like he literally turns into this dog he starts acting like dog and it just like what what are you doing it just really cheesy but kids you know laugh over it and think it really funny but you know as an adult it probably put you to sleep so if you are looking on to stay up with your kids like don run it because or don buy it because it much like dogs laugh but it just kinda cheesy so going to just give it two out of five star rating two so you know take that into consideration yeah two',\n",
              "       'hi going to review for you today the movie evan almighty umm this movie guess is supposed to be the sequel to bruce almighty but it pretty much completely different and doesn mention the first movie at all the only thing that the same is morgan freeman is still god lg and think uhh yeah think that pretty much the only thing like the same people did it but umm like obviously bruce doesn stutter evan almighty doesn get god powers or any of that like in the first one god just asks him to build an ark and says that if anybody asks there flood coming and umm he starts to do it because god makes it very hard for him to do his job as he congressman uhh newly appointed congressman and umm basically he can do anything else for the time unless he builds this ark and there lot of funny moments and it not as good as bruce almighty would say and they kind of stretched it little too far but it definitely really good for kids and there lot of funny moments so it was alright it wasn it wasn stutter too great',\n",
              "       'hi doing my video opinion for wolf rain leader of the pack this is the uhh first in the series this is an animated series and it pretty good show the first in particular like lot it contains the uhh first five episodes and really like the first episode it has lot of nice visuals some really nice music this show is umm it doesn really tell you if it in the future or not from now but it just like in different world it really harsh uhh humans are struggling to survive but there are also wolves which are well they they re stutter magic wolves then they can masquerade as humans walk around with humans and humans look at them and the look just like humans but they re really wolves and uhh there also like high count type people who seem to be humans but they re of like royal lineage and they want all the wolves dead and they fight them and there also humans that know about the wolves and uhh they can necessarily see them but they they stutter know that they exist and they they stutter wanna try to kill them they think that they re evil they think that they re bloodthirsty which isn always the case just like with humans and the wolves are on search for paradise it all very it uhh the whole show is just full of metaphors and it stutter really cool show though if you like think you should check out wolf rain the first give five out of five stars',\n",
              "       'hi today reviewing this movie this movie is called serenity uhh this is uhh the edition this movie was uhh written and directed by joss whedon and it basically the culmination of his storyline for his tv show firefly it has to do with uhh stutter aceship and its crew flying in the far reaches of ace in an alternate future uhh it world where umm there kind of an evil governmental group that seeks control of uhh everyone comings and goings and these guys are kind of rebels and outlaws they fly around in the ship and do what they want they re kind of mercenaries smugglers whatever they can do to make buck umm and this movie is like said the finale of all the that were supposed to be finished in the in the stutter cancelled tv series so there lot of lot of stutter subtext there for you if you go ahead and watch firefly first and then watch serenity you ll really know what going on but think the movie stands on its own ve oken with some people who ve only seen the movie and they really enjoyed it just for what it was it makes itself clear enough uhh ve got soft ot in my heart for this had to give it really high rating because liked it so much and think the characters are great uhh the the stutter actors are perfect for the roles and uhh some really really memorable characters in here uhh jane and uhh just everybody on the ship is really memorable give it huge thumbs up and big five you should watch this movie really good sci fi they don make them like this very often',\n",
              "       'this is the movie and uhh well this is sacha baron cohen and uhh as and the cultural of america for make benefit glorious nation of kazakhstan and uhh this is the of course and uhh it just uhh this is hilarious hilarious movie it just umm sacha baron cohen does great job with all his characters but ecially and uhh basically yeah uhh it it stutter if you ve ever seen uhh clips on his show then you just stutter like movie kind of stutters that he goes to the us and does these ridiculous things mean he just don even know how he can do some of the things that he does it just funny uhh uhh like running butt naked through dining room butt naked filled with you know stutter it looked like at least over hundred people and then wrestling with another man naked in front of everybody but umm the scenes stutter just completely ridiculous what goes on in this movie and it all just so funny uhh there deleted scenes there and there music infomercial uhh if you ve never seen the movie highly stutter even if you haven seen the the stutter clips from the show highly recommend it cause it very funny movie and give it five out of five',\n",
              "       'did review on the care bears movie this movie is rated umm everybody loves the care boar care bears uhh remember as kid uhh the care bears were uhh big thing they were just coming out uhh everybody had care bear doll they had care bear cartoons uhh well this is the care bear movie mean it uhh pretty good movie uhh the world in trouble and it uhh up to the care bears to save it and you know care bears uhh care about everybody they have their different uhh different characteristics uhh that they show but uhh in this one they re uhh they re uhh trying to save the world now uhh this does have voices of mickey rooney uhh georgia engel of uhh also its got songs that are uhh performed by carol king but in this movie uhh it great for uhh young kids uhh so do recommend picking it up uhh again they re trying to you know save the world uhh they watch over the earth and uhh make sure everybody kind and friendly uhh make sure nobody upset or anything uhh and mean even when evil uhh comes around uhh they still try to make everybody happy and uhh make people nice and everything so do recommend picking this up for your kids or mean as family you can watch it again that the care bears movie'],\n",
              "      dtype='<U4037')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH6cxMngWfrg",
        "colab_type": "code",
        "outputId": "f08ea548-8232-471d-eab5-1abb377add08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_pers[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.        , 3.66666667, 2.33333333, 4.        , 2.33333333,\n",
              "       1.66666667, 3.66666667, 4.66666667, 3.33333333, 2.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWbBXF9Ovzgr",
        "colab_type": "text"
      },
      "source": [
        "# ML Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQmxW28dv0-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dense_model():\n",
        "  \"\"\"\n",
        "  Returns:\n",
        "    dense model for proccessing word2vec embeddings\n",
        "  \"\"\"\n",
        "  embed_model = 'https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1'\n",
        "  hub_layer = hub.KerasLayer(embed_model, output_shape=[128], input_shape=[], dtype=tf.string, trainable=True)\n",
        "\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(hub_layer)\n",
        "  model.add(tf.keras.layers.Dense(64, activation=tf.keras.activations.relu))\n",
        "  model.add(tf.keras.layers.Dropout(.4))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dense(32, activation=tf.keras.activations.relu))\n",
        "  model.add(tf.keras.layers.Dense(1, activation=tf.keras.activations.linear))\n",
        "\n",
        "  model.compile(optimizer='adam', loss='mse')\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEmNMejX-p1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dense_doc2vec_classifier():\n",
        "  \"\"\"\n",
        "  Returns:\n",
        "    dense model for proccessing word2vec embeddings\n",
        "  \"\"\"\n",
        "  embed_model = 'https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1'\n",
        "  hub_layer = hub.KerasLayer(embed_model, output_shape=[128], input_shape=[], dtype=tf.string, trainable=True)\n",
        "\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(hub_layer)\n",
        "  model.add(tf.keras.layers.Dense(32, activation=tf.keras.activations.relu))\n",
        "  model.add(tf.keras.layers.Dropout(.2))\n",
        "  model.add(tf.keras.layers.Dense(32, activation=tf.keras.activations.relu))\n",
        "  model.add(tf.keras.layers.Dense(1, activation=tf.keras.activations.linear))\n",
        "\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoAh3AR9ICsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dense_classifier(input_dim):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "    input_dim: varies according to the number tfidf values\n",
        "  Returns:\n",
        "    NN dense model\n",
        "  \"\"\"\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(32, input_shape=(input_dim,), activation='sigmoid'))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "  model.add(tf.keras.layers.Dense(32,  activation='sigmoid'))\n",
        "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBG1-fP_9agJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_gradient_boosting_classifier(n_estimators=500):\n",
        "  return GradientBoostingClassifier(n_estimators=n_estimators, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3J45aOQtIUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_gradient_boosting_regressor(n_estimators=500):\n",
        "  return GradientBoostingRegressor(n_estimators=n_estimators, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVBsnPG2wK3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_random_forest_classifier(n_estimators=500):\n",
        "  return RandomForestClassifier(n_estimators=n_estimators, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8ZRye2GwL3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_random_forest_regressor(n_estimators=100):\n",
        "  return RandomForestRegressor(n_estimators=n_estimators, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-cYDHlky5nR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dummy_regressor(strategy='mean'):\n",
        "  return DummyRegressor(strategy=strategy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcu2ll09e6lf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dummy_classifier(strategy='most_frequent'):\n",
        "  return DummyClassifier(strategy=strategy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4tX2RwVB3HW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_svm_classifier(kernel='rbf'):\n",
        "  return SVC(kernel=kernel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f7dL97vXx1J",
        "colab_type": "text"
      },
      "source": [
        "# Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDnM5B2SzTW0",
        "colab_type": "text"
      },
      "source": [
        "## Baseline_Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch8VfZ5yzU19",
        "colab_type": "code",
        "outputId": "4965af36-53f2-408c-b9f6-bbbde1b35857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "kf = KFold(n_splits=5, shuffle=False)\n",
        "history = []\n",
        "for train_index, test_index in kf.split(X_text, y_pers):\n",
        "  X_text_train, X_text_test = X_text[train_index], X_text[test_index]\n",
        "  y_train, y_test = y_pers[train_index], y_pers[test_index]\n",
        "\n",
        "  dummy = get_dummy_regressor()\n",
        "  dummy.fit(X_text_train, y_train)\n",
        "\n",
        "  y_pred = dummy.predict(X_text_test)\n",
        "  mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "  history.append(mae)\n",
        "  print(\"Fold-------\")\n",
        "  print(\"X_text_train shape: {} | y_train shape: {}\".format(X_text_train.shape, y_train.shape))\n",
        "  print(\"X_text_test shape: {} | y_test shape: {}\".format(X_text_test.shape, y_test.shape))\n",
        "\n",
        "  print(\"Mean_Absolute_Error: {}\".format(mae))\n",
        "print(\"Mean_MAE: {}\".format(np.mean(history)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold-------\n",
            "X_text_train shape: (722,) | y_train shape: (722,)\n",
            "X_text_test shape: (181,) | y_test shape: (181,)\n",
            "Mean_Absolute_Error: 1.1274506052861142\n",
            "Fold-------\n",
            "X_text_train shape: (722,) | y_train shape: (722,)\n",
            "X_text_test shape: (181,) | y_test shape: (181,)\n",
            "Mean_Absolute_Error: 1.0350430816791907\n",
            "Fold-------\n",
            "X_text_train shape: (722,) | y_train shape: (722,)\n",
            "X_text_test shape: (181,) | y_test shape: (181,)\n",
            "Mean_Absolute_Error: 1.1725856149533473\n",
            "Fold-------\n",
            "X_text_train shape: (723,) | y_train shape: (723,)\n",
            "X_text_test shape: (180,) | y_test shape: (180,)\n",
            "Mean_Absolute_Error: 1.0529596332155116\n",
            "Fold-------\n",
            "X_text_train shape: (723,) | y_train shape: (723,)\n",
            "X_text_test shape: (180,) | y_test shape: (180,)\n",
            "Mean_Absolute_Error: 1.131407202499872\n",
            "Mean_MAE: 1.1038892275268073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIqVPzTfedyC",
        "colab_type": "text"
      },
      "source": [
        "## Baseline_Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENEofmWqef-K",
        "colab_type": "code",
        "outputId": "1bb97c66-7ce8-4feb-8440-b0a2d5fd3c2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "kf = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "history = []\n",
        "for train_index, test_index in kf.split(X_text_pers, y_binary_pers):\n",
        "  X_text_train, X_text_test = X_text_pers[train_index], X_text_pers[test_index]\n",
        "  y_train, y_test = y_binary_pers[train_index], y_binary_pers[test_index]\n",
        "\n",
        "  dummy = get_dummy_classifier()\n",
        "  dummy.fit(X_text_train, y_train)\n",
        "\n",
        "  y_pred = dummy.predict(X_text_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "  history.append(accuracy)\n",
        "  print(\"Fold-------\")\n",
        "  print(\"X_text_train shape: {} | y_train shape: {}\".format(X_text_train.shape, y_train.shape))\n",
        "  print(\"X_text_test shape: {} | y_test shape: {}\".format(X_text_test.shape, y_test.shape))\n",
        "\n",
        "  print(\"Accuracy: {}\".format(accuracy))\n",
        "print(\"Mean_Accuracy: {}\".format(np.mean(history)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.5194805194805194\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.5194805194805194\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.5064935064935064\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.5064935064935064\n",
            "Fold-------\n",
            "X_text_train shape: (308,) | y_train shape: (308,)\n",
            "X_text_test shape: (76,) | y_test shape: (76,)\n",
            "Accuracy: 0.5131578947368421\n",
            "Mean_Accuracy: 0.5130211893369788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7qJOY7lMyXj",
        "colab_type": "text"
      },
      "source": [
        "# Doc2Vec embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRRgIbBKA8-k",
        "colab_type": "code",
        "outputId": "484dedf6-3ff1-431c-b996-8f4bea272c35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kf = KFold(n_splits=5, shuffle=False)\n",
        "history = []\n",
        "for train_index, test_index in kf.split(X_text, y_pers):\n",
        "  X_text_train, X_text_test = X_text[train_index], X_text[test_index]\n",
        "  y_train, y_test = y_pers[train_index], y_pers[test_index]\n",
        "\n",
        "  dense = get_dense_model()\n",
        "  dense.fit(X_text_train, y_train, batch_size=32, epochs=50, verbose=1, validation_split=.1)\n",
        "  \n",
        "  y_pred = dense.predict(X_text_test)\n",
        "  mae = mean_absolute_error(y_test, y_pred)\n",
        "  \n",
        "  history.append(mae)\n",
        "  print(\"Fold-------\")\n",
        "  print(\"X_text_train shape: {} | y_train shape: {}\".format(X_text_train.shape, y_train.shape))\n",
        "  print(\"X_text_test shape: {} | y_test shape: {}\".format(X_text_test.shape, y_test.shape))\n",
        "\n",
        "  print(\"Mean_Absolute_Error: {}\".format(mae))\n",
        "print(\"Mean_MAE: {}\".format(np.mean(history)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "21/21 [==============================] - 2s 81ms/step - loss: 14.8159 - msle: 1.6338 - val_loss: 16.3380 - val_msle: 1.8600\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 2s 80ms/step - loss: 10.3257 - msle: 0.9282 - val_loss: 13.6484 - val_msle: 1.2825\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 5.7343 - msle: 0.3788 - val_loss: 9.8978 - val_msle: 0.7163\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 2.8479 - msle: 0.1484 - val_loss: 7.0373 - val_msle: 0.4173\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 1.7465 - msle: 0.0812 - val_loss: 5.0567 - val_msle: 0.2595\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 1.3470 - msle: 0.0622 - val_loss: 4.1256 - val_msle: 0.1972\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 1.1107 - msle: 0.0516 - val_loss: 3.3745 - val_msle: 0.1530\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.9764 - msle: 0.0442 - val_loss: 3.1523 - val_msle: 0.1392\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.9148 - msle: 0.0415 - val_loss: 2.8885 - val_msle: 0.1260\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.7590 - msle: 0.0366 - val_loss: 2.8342 - val_msle: 0.1253\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.6691 - msle: 0.0340 - val_loss: 2.1285 - val_msle: 0.0906\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.6064 - msle: 0.0288 - val_loss: 2.5593 - val_msle: 0.1127\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.6865 - msle: 0.0342 - val_loss: 2.5130 - val_msle: 0.1107\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.6037 - msle: 0.0289 - val_loss: 2.2605 - val_msle: 0.0988\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.5598 - msle: 0.0270 - val_loss: 1.8359 - val_msle: 0.0790\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.5284 - msle: 0.0275 - val_loss: 1.9884 - val_msle: 0.0867\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.4817 - msle: 0.0234 - val_loss: 1.4974 - val_msle: 0.0666\n",
            "Epoch 18/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.4529 - msle: 0.0237 - val_loss: 1.5673 - val_msle: 0.0682\n",
            "Epoch 19/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.4907 - msle: 0.0241 - val_loss: 1.8364 - val_msle: 0.0810\n",
            "Epoch 20/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.4657 - msle: 0.0242 - val_loss: 1.4107 - val_msle: 0.0636\n",
            "Epoch 21/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.4229 - msle: 0.0204 - val_loss: 1.5457 - val_msle: 0.0701\n",
            "Epoch 22/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3973 - msle: 0.0204 - val_loss: 1.4595 - val_msle: 0.0669\n",
            "Epoch 23/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3858 - msle: 0.0192 - val_loss: 1.3367 - val_msle: 0.0633\n",
            "Epoch 24/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.4240 - msle: 0.0215 - val_loss: 1.3323 - val_msle: 0.0632\n",
            "Epoch 25/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3289 - msle: 0.0168 - val_loss: 1.2658 - val_msle: 0.0589\n",
            "Epoch 26/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3982 - msle: 0.0195 - val_loss: 1.1911 - val_msle: 0.0554\n",
            "Epoch 27/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3483 - msle: 0.0206 - val_loss: 1.2236 - val_msle: 0.0569\n",
            "Epoch 28/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.3792 - msle: 0.0189 - val_loss: 1.2272 - val_msle: 0.0578\n",
            "Epoch 29/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.3323 - msle: 0.0167 - val_loss: 1.2481 - val_msle: 0.0587\n",
            "Epoch 30/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3359 - msle: 0.0171 - val_loss: 1.2082 - val_msle: 0.0576\n",
            "Epoch 31/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.3383 - msle: 0.0169 - val_loss: 1.3678 - val_msle: 0.0642\n",
            "Epoch 32/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.3702 - msle: 0.0185 - val_loss: 1.5779 - val_msle: 0.0757\n",
            "Epoch 33/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.3263 - msle: 0.0151 - val_loss: 1.7003 - val_msle: 0.0803\n",
            "Epoch 34/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3337 - msle: 0.0173 - val_loss: 1.2395 - val_msle: 0.0597\n",
            "Epoch 35/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.3373 - msle: 0.0168 - val_loss: 1.4074 - val_msle: 0.0672\n",
            "Epoch 36/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.3171 - msle: 0.0165 - val_loss: 1.4306 - val_msle: 0.0674\n",
            "Epoch 37/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3345 - msle: 0.0165 - val_loss: 1.6387 - val_msle: 0.0770\n",
            "Epoch 38/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3111 - msle: 0.0156 - val_loss: 1.4717 - val_msle: 0.0715\n",
            "Epoch 39/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2995 - msle: 0.0162 - val_loss: 1.2759 - val_msle: 0.0618\n",
            "Epoch 40/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2970 - msle: 0.0154 - val_loss: 1.3033 - val_msle: 0.0615\n",
            "Epoch 41/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2957 - msle: 0.0142 - val_loss: 1.3391 - val_msle: 0.0639\n",
            "Epoch 42/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3292 - msle: 0.0176 - val_loss: 1.3148 - val_msle: 0.0635\n",
            "Epoch 43/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.3079 - msle: 0.0150 - val_loss: 1.3500 - val_msle: 0.0649\n",
            "Epoch 44/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2827 - msle: 0.0157 - val_loss: 1.2793 - val_msle: 0.0618\n",
            "Epoch 45/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3081 - msle: 0.0173 - val_loss: 1.3834 - val_msle: 0.0665\n",
            "Epoch 46/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2711 - msle: 0.0148 - val_loss: 1.2983 - val_msle: 0.0629\n",
            "Epoch 47/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.2951 - msle: 0.0152 - val_loss: 1.5076 - val_msle: 0.0733\n",
            "Epoch 48/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2681 - msle: 0.0136 - val_loss: 1.3144 - val_msle: 0.0624\n",
            "Epoch 49/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2814 - msle: 0.0163 - val_loss: 1.2776 - val_msle: 0.0622\n",
            "Epoch 50/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2555 - msle: 0.0130 - val_loss: 1.3382 - val_msle: 0.0648\n",
            "Fold-------\n",
            "X_text_train shape: (722,) | y_train shape: (722,)\n",
            "X_text_test shape: (181,) | y_test shape: (181,)\n",
            "Mean_Absolute_Error: 1.0613709725508156\n",
            "Epoch 1/50\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 15.3877 - msle: 1.6899 - val_loss: 13.8382 - val_msle: 1.3162\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 10.5002 - msle: 0.9857 - val_loss: 11.5450 - val_msle: 0.9397\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 6.4483 - msle: 0.4849 - val_loss: 10.0071 - val_msle: 0.7410\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 3.7110 - msle: 0.2267 - val_loss: 7.4060 - val_msle: 0.4613\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 2.2469 - msle: 0.1146 - val_loss: 5.5258 - val_msle: 0.2946\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 1.6283 - msle: 0.0774 - val_loss: 4.7759 - val_msle: 0.2376\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 1.3676 - msle: 0.0622 - val_loss: 4.5639 - val_msle: 0.2220\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 1.1396 - msle: 0.0521 - val_loss: 4.4111 - val_msle: 0.2136\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 1.0108 - msle: 0.0471 - val_loss: 4.7721 - val_msle: 0.2364\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.8359 - msle: 0.0414 - val_loss: 3.5973 - val_msle: 0.1626\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.7845 - msle: 0.0373 - val_loss: 2.7892 - val_msle: 0.1183\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.8437 - msle: 0.0391 - val_loss: 2.9355 - val_msle: 0.1263\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.6636 - msle: 0.0322 - val_loss: 2.7049 - val_msle: 0.1171\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.6224 - msle: 0.0302 - val_loss: 2.1342 - val_msle: 0.0894\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.6642 - msle: 0.0368 - val_loss: 2.4774 - val_msle: 0.1043\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.5563 - msle: 0.0291 - val_loss: 1.6807 - val_msle: 0.0680\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.5082 - msle: 0.0258 - val_loss: 2.0964 - val_msle: 0.0860\n",
            "Epoch 18/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.6248 - msle: 0.0298 - val_loss: 1.8199 - val_msle: 0.0740\n",
            "Epoch 19/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5384 - msle: 0.0269 - val_loss: 1.5847 - val_msle: 0.0648\n",
            "Epoch 20/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.5229 - msle: 0.0252 - val_loss: 1.3980 - val_msle: 0.0574\n",
            "Epoch 21/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.4004 - msle: 0.0200 - val_loss: 1.5933 - val_msle: 0.0646\n",
            "Epoch 22/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.4694 - msle: 0.0219 - val_loss: 1.2575 - val_msle: 0.0520\n",
            "Epoch 23/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.4449 - msle: 0.0219 - val_loss: 1.1510 - val_msle: 0.0487\n",
            "Epoch 24/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.4739 - msle: 0.0232 - val_loss: 1.3993 - val_msle: 0.0566\n",
            "Epoch 25/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.4197 - msle: 0.0202 - val_loss: 1.2529 - val_msle: 0.0513\n",
            "Epoch 26/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.4174 - msle: 0.0224 - val_loss: 1.4591 - val_msle: 0.0595\n",
            "Epoch 27/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.4051 - msle: 0.0217 - val_loss: 1.5412 - val_msle: 0.0633\n",
            "Epoch 28/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.4036 - msle: 0.0203 - val_loss: 1.3410 - val_msle: 0.0561\n",
            "Epoch 29/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3694 - msle: 0.0191 - val_loss: 1.3469 - val_msle: 0.0560\n",
            "Epoch 30/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.3299 - msle: 0.0165 - val_loss: 1.5945 - val_msle: 0.0654\n",
            "Epoch 31/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.3544 - msle: 0.0181 - val_loss: 1.3445 - val_msle: 0.0544\n",
            "Epoch 32/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.3636 - msle: 0.0189 - val_loss: 1.4560 - val_msle: 0.0587\n",
            "Epoch 33/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3078 - msle: 0.0163 - val_loss: 1.4291 - val_msle: 0.0589\n",
            "Epoch 34/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3498 - msle: 0.0182 - val_loss: 1.3181 - val_msle: 0.0548\n",
            "Epoch 35/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3534 - msle: 0.0191 - val_loss: 1.4946 - val_msle: 0.0622\n",
            "Epoch 36/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.3591 - msle: 0.0188 - val_loss: 1.3526 - val_msle: 0.0572\n",
            "Epoch 37/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.3157 - msle: 0.0167 - val_loss: 1.4490 - val_msle: 0.0616\n",
            "Epoch 38/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2891 - msle: 0.0150 - val_loss: 1.1763 - val_msle: 0.0501\n",
            "Epoch 39/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.3489 - msle: 0.0186 - val_loss: 1.2515 - val_msle: 0.0522\n",
            "Epoch 40/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3546 - msle: 0.0178 - val_loss: 1.2069 - val_msle: 0.0502\n",
            "Epoch 41/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3125 - msle: 0.0178 - val_loss: 1.3032 - val_msle: 0.0547\n",
            "Epoch 42/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.2760 - msle: 0.0139 - val_loss: 1.2779 - val_msle: 0.0540\n",
            "Epoch 43/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2880 - msle: 0.0154 - val_loss: 1.0258 - val_msle: 0.0444\n",
            "Epoch 44/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.2843 - msle: 0.0147 - val_loss: 1.5017 - val_msle: 0.0636\n",
            "Epoch 45/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2262 - msle: 0.0126 - val_loss: 1.1036 - val_msle: 0.0475\n",
            "Epoch 46/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2884 - msle: 0.0145 - val_loss: 1.1605 - val_msle: 0.0509\n",
            "Epoch 47/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.3118 - msle: 0.0154 - val_loss: 1.3562 - val_msle: 0.0580\n",
            "Epoch 48/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.2724 - msle: 0.0141 - val_loss: 1.1775 - val_msle: 0.0508\n",
            "Epoch 49/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.2852 - msle: 0.0145 - val_loss: 1.2129 - val_msle: 0.0520\n",
            "Epoch 50/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.3037 - msle: 0.0164 - val_loss: 1.2163 - val_msle: 0.0511\n",
            "Fold-------\n",
            "X_text_train shape: (722,) | y_train shape: (722,)\n",
            "X_text_test shape: (181,) | y_test shape: (181,)\n",
            "Mean_Absolute_Error: 0.9874238941550914\n",
            "Epoch 1/50\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 17.3024 - msle: 1.9473 - val_loss: 15.8893 - val_msle: 1.7473\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 12.4010 - msle: 1.3286 - val_loss: 11.8792 - val_msle: 0.9816\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 8.1346 - msle: 0.7287 - val_loss: 8.8504 - val_msle: 0.5973\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 4.7067 - msle: 0.3375 - val_loss: 6.7312 - val_msle: 0.3941\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 2.4560 - msle: 0.1434 - val_loss: 4.4172 - val_msle: 0.2180\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 1.4940 - msle: 0.0711 - val_loss: 3.4834 - val_msle: 0.1581\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 1.3257 - msle: 0.0622 - val_loss: 2.8470 - val_msle: 0.1220\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 1.0628 - msle: 0.0512 - val_loss: 2.4535 - val_msle: 0.1033\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.9408 - msle: 0.0458 - val_loss: 2.4555 - val_msle: 0.1037\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.8491 - msle: 0.0402 - val_loss: 2.5322 - val_msle: 0.1089\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.7357 - msle: 0.0370 - val_loss: 2.0749 - val_msle: 0.0856\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.6881 - msle: 0.0336 - val_loss: 1.6985 - val_msle: 0.0697\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.6320 - msle: 0.0318 - val_loss: 1.7186 - val_msle: 0.0703\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5476 - msle: 0.0261 - val_loss: 1.8264 - val_msle: 0.0767\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.5182 - msle: 0.0263 - val_loss: 1.5898 - val_msle: 0.0663\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.5050 - msle: 0.0276 - val_loss: 1.8244 - val_msle: 0.0779\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.5618 - msle: 0.0280 - val_loss: 1.4318 - val_msle: 0.0603\n",
            "Epoch 18/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.4526 - msle: 0.0240 - val_loss: 1.4932 - val_msle: 0.0628\n",
            "Epoch 19/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.3856 - msle: 0.0191 - val_loss: 1.5999 - val_msle: 0.0681\n",
            "Epoch 20/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.4032 - msle: 0.0207 - val_loss: 1.5013 - val_msle: 0.0648\n",
            "Epoch 21/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.4245 - msle: 0.0214 - val_loss: 1.3908 - val_msle: 0.0609\n",
            "Epoch 22/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3746 - msle: 0.0196 - val_loss: 1.5159 - val_msle: 0.0651\n",
            "Epoch 23/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.3533 - msle: 0.0172 - val_loss: 1.3913 - val_msle: 0.0603\n",
            "Epoch 24/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.4023 - msle: 0.0195 - val_loss: 1.2739 - val_msle: 0.0560\n",
            "Epoch 25/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3959 - msle: 0.0192 - val_loss: 1.4815 - val_msle: 0.0665\n",
            "Epoch 26/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3732 - msle: 0.0192 - val_loss: 1.4028 - val_msle: 0.0626\n",
            "Epoch 27/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.3847 - msle: 0.0205 - val_loss: 1.5944 - val_msle: 0.0713\n",
            "Epoch 28/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.3715 - msle: 0.0182 - val_loss: 1.3173 - val_msle: 0.0581\n",
            "Epoch 29/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3411 - msle: 0.0176 - val_loss: 1.3703 - val_msle: 0.0603\n",
            "Epoch 30/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.3700 - msle: 0.0190 - val_loss: 1.2144 - val_msle: 0.0539\n",
            "Epoch 31/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3102 - msle: 0.0162 - val_loss: 1.2433 - val_msle: 0.0545\n",
            "Epoch 32/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3523 - msle: 0.0181 - val_loss: 1.3595 - val_msle: 0.0597\n",
            "Epoch 33/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.3161 - msle: 0.0165 - val_loss: 1.2445 - val_msle: 0.0547\n",
            "Epoch 34/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3249 - msle: 0.0175 - val_loss: 1.5581 - val_msle: 0.0697\n",
            "Epoch 35/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2844 - msle: 0.0155 - val_loss: 1.1745 - val_msle: 0.0526\n",
            "Epoch 36/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3140 - msle: 0.0166 - val_loss: 1.5932 - val_msle: 0.0728\n",
            "Epoch 37/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2866 - msle: 0.0142 - val_loss: 1.3307 - val_msle: 0.0596\n",
            "Epoch 38/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.2824 - msle: 0.0140 - val_loss: 1.2959 - val_msle: 0.0578\n",
            "Epoch 39/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2642 - msle: 0.0137 - val_loss: 1.3187 - val_msle: 0.0586\n",
            "Epoch 40/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.2984 - msle: 0.0159 - val_loss: 1.2703 - val_msle: 0.0558\n",
            "Epoch 41/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.2516 - msle: 0.0131 - val_loss: 1.3808 - val_msle: 0.0607\n",
            "Epoch 42/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.2566 - msle: 0.0130 - val_loss: 1.2332 - val_msle: 0.0544\n",
            "Epoch 43/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2524 - msle: 0.0125 - val_loss: 1.3093 - val_msle: 0.0578\n",
            "Epoch 44/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2859 - msle: 0.0150 - val_loss: 1.2844 - val_msle: 0.0567\n",
            "Epoch 45/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.2481 - msle: 0.0130 - val_loss: 1.2848 - val_msle: 0.0566\n",
            "Epoch 46/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.2592 - msle: 0.0139 - val_loss: 1.2066 - val_msle: 0.0540\n",
            "Epoch 47/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.2943 - msle: 0.0141 - val_loss: 1.2985 - val_msle: 0.0582\n",
            "Epoch 48/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.2416 - msle: 0.0124 - val_loss: 1.4576 - val_msle: 0.0663\n",
            "Epoch 49/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2671 - msle: 0.0141 - val_loss: 1.3533 - val_msle: 0.0611\n",
            "Epoch 50/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.2566 - msle: 0.0145 - val_loss: 1.3337 - val_msle: 0.0596\n",
            "Fold-------\n",
            "X_text_train shape: (722,) | y_train shape: (722,)\n",
            "X_text_test shape: (181,) | y_test shape: (181,)\n",
            "Mean_Absolute_Error: 1.15014642158705\n",
            "Epoch 1/50\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 13.1872 - msle: 1.3775 - val_loss: 15.5313 - val_msle: 1.6607\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 7.9265 - msle: 0.6602 - val_loss: 10.8508 - val_msle: 0.8316\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 4.4175 - msle: 0.2911 - val_loss: 7.4918 - val_msle: 0.4560\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 2.4409 - msle: 0.1244 - val_loss: 5.5076 - val_msle: 0.2900\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 1.7703 - msle: 0.0881 - val_loss: 4.7969 - val_msle: 0.2415\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 1.3128 - msle: 0.0652 - val_loss: 4.4364 - val_msle: 0.2169\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 1.2259 - msle: 0.0574 - val_loss: 3.1261 - val_msle: 0.1375\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 1.1051 - msle: 0.0529 - val_loss: 2.9017 - val_msle: 0.1272\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 1.0136 - msle: 0.0481 - val_loss: 3.4503 - val_msle: 0.1580\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.8594 - msle: 0.0420 - val_loss: 2.5200 - val_msle: 0.1087\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.8587 - msle: 0.0403 - val_loss: 2.9814 - val_msle: 0.1348\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.6846 - msle: 0.0341 - val_loss: 2.0683 - val_msle: 0.0881\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.7405 - msle: 0.0356 - val_loss: 2.3422 - val_msle: 0.1016\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.6999 - msle: 0.0334 - val_loss: 2.2423 - val_msle: 0.0974\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.6210 - msle: 0.0310 - val_loss: 2.3016 - val_msle: 0.0995\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.5716 - msle: 0.0282 - val_loss: 1.7505 - val_msle: 0.0754\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.5396 - msle: 0.0279 - val_loss: 1.8717 - val_msle: 0.0810\n",
            "Epoch 18/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5657 - msle: 0.0280 - val_loss: 1.6001 - val_msle: 0.0679\n",
            "Epoch 19/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5277 - msle: 0.0264 - val_loss: 1.4995 - val_msle: 0.0640\n",
            "Epoch 20/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.5372 - msle: 0.0268 - val_loss: 1.4215 - val_msle: 0.0613\n",
            "Epoch 21/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.5961 - msle: 0.0301 - val_loss: 1.7339 - val_msle: 0.0757\n",
            "Epoch 22/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.4423 - msle: 0.0230 - val_loss: 1.4637 - val_msle: 0.0648\n",
            "Epoch 23/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.4881 - msle: 0.0239 - val_loss: 1.4373 - val_msle: 0.0650\n",
            "Epoch 24/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.4603 - msle: 0.0240 - val_loss: 1.5382 - val_msle: 0.0680\n",
            "Epoch 25/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.4252 - msle: 0.0220 - val_loss: 1.3007 - val_msle: 0.0589\n",
            "Epoch 26/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.4179 - msle: 0.0228 - val_loss: 1.2767 - val_msle: 0.0585\n",
            "Epoch 27/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.4389 - msle: 0.0247 - val_loss: 1.6414 - val_msle: 0.0739\n",
            "Epoch 28/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3947 - msle: 0.0216 - val_loss: 1.3319 - val_msle: 0.0603\n",
            "Epoch 29/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.3926 - msle: 0.0190 - val_loss: 1.3863 - val_msle: 0.0643\n",
            "Epoch 30/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.3792 - msle: 0.0201 - val_loss: 1.7018 - val_msle: 0.0776\n",
            "Epoch 31/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.3710 - msle: 0.0201 - val_loss: 1.5804 - val_msle: 0.0728\n",
            "Epoch 32/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3780 - msle: 0.0208 - val_loss: 1.3015 - val_msle: 0.0600\n",
            "Epoch 33/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.3898 - msle: 0.0201 - val_loss: 1.4465 - val_msle: 0.0659\n",
            "Epoch 34/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.3450 - msle: 0.0169 - val_loss: 1.4387 - val_msle: 0.0667\n",
            "Epoch 35/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.3457 - msle: 0.0206 - val_loss: 1.4881 - val_msle: 0.0690\n",
            "Epoch 36/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.3384 - msle: 0.0190 - val_loss: 1.3485 - val_msle: 0.0618\n",
            "Epoch 37/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3251 - msle: 0.0172 - val_loss: 1.3799 - val_msle: 0.0624\n",
            "Epoch 38/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2934 - msle: 0.0167 - val_loss: 1.4019 - val_msle: 0.0645\n",
            "Epoch 39/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2961 - msle: 0.0145 - val_loss: 1.3347 - val_msle: 0.0615\n",
            "Epoch 40/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2805 - msle: 0.0167 - val_loss: 1.4063 - val_msle: 0.0639\n",
            "Epoch 41/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3428 - msle: 0.0185 - val_loss: 1.4041 - val_msle: 0.0645\n",
            "Epoch 42/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2940 - msle: 0.0158 - val_loss: 1.2678 - val_msle: 0.0581\n",
            "Epoch 43/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2610 - msle: 0.0134 - val_loss: 1.5520 - val_msle: 0.0706\n",
            "Epoch 44/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3511 - msle: 0.0173 - val_loss: 1.2591 - val_msle: 0.0592\n",
            "Epoch 45/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3154 - msle: 0.0167 - val_loss: 1.4182 - val_msle: 0.0658\n",
            "Epoch 46/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.3033 - msle: 0.0166 - val_loss: 1.3548 - val_msle: 0.0625\n",
            "Epoch 47/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.2784 - msle: 0.0148 - val_loss: 1.2849 - val_msle: 0.0595\n",
            "Epoch 48/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2910 - msle: 0.0172 - val_loss: 1.2738 - val_msle: 0.0599\n",
            "Epoch 49/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2893 - msle: 0.0167 - val_loss: 1.4661 - val_msle: 0.0695\n",
            "Epoch 50/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.2698 - msle: 0.0141 - val_loss: 1.4018 - val_msle: 0.0657\n",
            "Fold-------\n",
            "X_text_train shape: (723,) | y_train shape: (723,)\n",
            "X_text_test shape: (180,) | y_test shape: (180,)\n",
            "Mean_Absolute_Error: 1.113900218628071\n",
            "Epoch 1/50\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 15.1088 - msle: 1.6505 - val_loss: 12.3911 - val_msle: 1.1975\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 9.8095 - msle: 0.8570 - val_loss: 10.5008 - val_msle: 0.8705\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 5.6456 - msle: 0.3796 - val_loss: 7.8928 - val_msle: 0.5262\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 2.7033 - msle: 0.1318 - val_loss: 6.0085 - val_msle: 0.3426\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 1.7211 - msle: 0.0778 - val_loss: 4.4054 - val_msle: 0.2194\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 1.5826 - msle: 0.0709 - val_loss: 3.8591 - val_msle: 0.1828\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 1.2890 - msle: 0.0563 - val_loss: 3.0727 - val_msle: 0.1378\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 1.1731 - msle: 0.0525 - val_loss: 2.6538 - val_msle: 0.1175\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 1.0433 - msle: 0.0473 - val_loss: 2.6556 - val_msle: 0.1173\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.8987 - msle: 0.0417 - val_loss: 2.9527 - val_msle: 0.1315\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.7771 - msle: 0.0352 - val_loss: 2.4453 - val_msle: 0.1081\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.7134 - msle: 0.0322 - val_loss: 2.1040 - val_msle: 0.0956\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.7276 - msle: 0.0321 - val_loss: 2.1200 - val_msle: 0.0964\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5820 - msle: 0.0267 - val_loss: 2.2175 - val_msle: 0.1000\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.6001 - msle: 0.0262 - val_loss: 2.0847 - val_msle: 0.0965\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.5587 - msle: 0.0249 - val_loss: 2.0550 - val_msle: 0.0953\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5696 - msle: 0.0259 - val_loss: 2.0973 - val_msle: 0.0973\n",
            "Epoch 18/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5134 - msle: 0.0246 - val_loss: 1.9417 - val_msle: 0.0925\n",
            "Epoch 19/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.5040 - msle: 0.0225 - val_loss: 2.0522 - val_msle: 0.0965\n",
            "Epoch 20/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.4676 - msle: 0.0201 - val_loss: 1.8510 - val_msle: 0.0909\n",
            "Epoch 21/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.4682 - msle: 0.0200 - val_loss: 1.9070 - val_msle: 0.0921\n",
            "Epoch 22/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5067 - msle: 0.0240 - val_loss: 1.9842 - val_msle: 0.0958\n",
            "Epoch 23/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.4846 - msle: 0.0227 - val_loss: 2.0524 - val_msle: 0.0968\n",
            "Epoch 24/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.4616 - msle: 0.0216 - val_loss: 2.0035 - val_msle: 0.0942\n",
            "Epoch 25/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.4483 - msle: 0.0206 - val_loss: 1.8707 - val_msle: 0.0919\n",
            "Epoch 26/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.4057 - msle: 0.0186 - val_loss: 1.9626 - val_msle: 0.0944\n",
            "Epoch 27/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3772 - msle: 0.0175 - val_loss: 1.8871 - val_msle: 0.0926\n",
            "Epoch 28/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.4325 - msle: 0.0198 - val_loss: 1.9293 - val_msle: 0.0936\n",
            "Epoch 29/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3702 - msle: 0.0182 - val_loss: 2.1502 - val_msle: 0.1004\n",
            "Epoch 30/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3886 - msle: 0.0186 - val_loss: 1.9776 - val_msle: 0.0961\n",
            "Epoch 31/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3373 - msle: 0.0150 - val_loss: 2.0359 - val_msle: 0.0980\n",
            "Epoch 32/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3858 - msle: 0.0184 - val_loss: 1.9006 - val_msle: 0.0934\n",
            "Epoch 33/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.3535 - msle: 0.0154 - val_loss: 1.9101 - val_msle: 0.0936\n",
            "Epoch 34/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3366 - msle: 0.0152 - val_loss: 2.0596 - val_msle: 0.0983\n",
            "Epoch 35/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2972 - msle: 0.0145 - val_loss: 1.9724 - val_msle: 0.0953\n",
            "Epoch 36/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.3297 - msle: 0.0152 - val_loss: 2.2032 - val_msle: 0.1050\n",
            "Epoch 37/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3186 - msle: 0.0151 - val_loss: 1.9528 - val_msle: 0.0971\n",
            "Epoch 38/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2781 - msle: 0.0125 - val_loss: 2.1657 - val_msle: 0.1033\n",
            "Epoch 39/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3022 - msle: 0.0146 - val_loss: 2.3274 - val_msle: 0.1127\n",
            "Epoch 40/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3186 - msle: 0.0153 - val_loss: 2.0733 - val_msle: 0.1005\n",
            "Epoch 41/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2998 - msle: 0.0135 - val_loss: 2.1115 - val_msle: 0.0998\n",
            "Epoch 42/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.3085 - msle: 0.0151 - val_loss: 2.0738 - val_msle: 0.1014\n",
            "Epoch 43/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2893 - msle: 0.0133 - val_loss: 2.0834 - val_msle: 0.1017\n",
            "Epoch 44/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.2821 - msle: 0.0137 - val_loss: 2.0468 - val_msle: 0.1005\n",
            "Epoch 45/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2650 - msle: 0.0132 - val_loss: 2.0173 - val_msle: 0.0994\n",
            "Epoch 46/50\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.2758 - msle: 0.0133 - val_loss: 2.0016 - val_msle: 0.0995\n",
            "Epoch 47/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2252 - msle: 0.0110 - val_loss: 1.9455 - val_msle: 0.0967\n",
            "Epoch 48/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.2595 - msle: 0.0124 - val_loss: 2.0014 - val_msle: 0.1000\n",
            "Epoch 49/50\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.2519 - msle: 0.0116 - val_loss: 2.1734 - val_msle: 0.1089\n",
            "Epoch 50/50\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.2334 - msle: 0.0112 - val_loss: 1.9074 - val_msle: 0.0927\n",
            "Fold-------\n",
            "X_text_train shape: (723,) | y_train shape: (723,)\n",
            "X_text_test shape: (180,) | y_test shape: (180,)\n",
            "Mean_Absolute_Error: 1.0448902355300056\n",
            "Mean_MAE: 1.0715463484902068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvAlIk9L-7bV",
        "colab_type": "code",
        "outputId": "f39ebfac-c3f7-4375-8522-369353637198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kf = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "history = []\n",
        "for train_index, test_index in kf.split(X_text_pers, y_binary_pers):\n",
        "  X_text_train, X_text_test = X_text_pers[train_index], X_text_pers[test_index]\n",
        "  y_train, y_test = y_binary_pers[train_index], y_binary_pers[test_index]\n",
        "\n",
        "  dense = get_dense_doc2vec_classifier()\n",
        "  dense.fit(X_text_train, y_train, batch_size=32, epochs=50, verbose=1, validation_split=.1)\n",
        "  \n",
        "  y_pred = dense.predict_classes(X_text_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  \n",
        "  history.append(accuracy)\n",
        "  print(\"Fold-------\")\n",
        "  print(\"X_text_train shape: {} | y_train shape: {}\".format(X_text_train.shape, y_train.shape))\n",
        "  print(\"X_text_test shape: {} | y_test shape: {}\".format(X_text_test.shape, y_test.shape))\n",
        "\n",
        "  print(\"Accuracy: {}\".format(accuracy))\n",
        "print(\"Mean_Accuracy: {}\".format(np.mean(history)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 1.0432 - val_loss: 0.8678\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.6483 - val_loss: 0.7313\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.5716 - val_loss: 0.6056\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.4828 - val_loss: 0.6386\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.3843 - val_loss: 0.5707\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.2952 - val_loss: 0.5541\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.2319 - val_loss: 0.4939\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.1381 - val_loss: 0.5238\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0867 - val_loss: 0.4684\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0682 - val_loss: 1.4073\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0512 - val_loss: 0.4982\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0438 - val_loss: 0.4393\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0199 - val_loss: 1.3963\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0230 - val_loss: 1.3111\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0104 - val_loss: 0.8641\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0124 - val_loss: 1.3138\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0073 - val_loss: 1.3403\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0109 - val_loss: 1.2709\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0058 - val_loss: 1.2819\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0019 - val_loss: 1.3177\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0048 - val_loss: 1.3144\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0071 - val_loss: 1.2669\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0032 - val_loss: 1.2858\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0075 - val_loss: 1.3000\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0038 - val_loss: 1.3550\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0017 - val_loss: 1.3921\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0031 - val_loss: 1.4153\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0032 - val_loss: 1.3700\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0015 - val_loss: 1.2857\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 1.6471e-04 - val_loss: 1.2761\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0028 - val_loss: 1.3180\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0020 - val_loss: 1.3116\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0047 - val_loss: 1.2499\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.0014 - val_loss: 1.2346\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0023 - val_loss: 1.2499\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 1s 68ms/step - loss: 0.0019 - val_loss: 1.3400\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 3.4162e-04 - val_loss: 1.5725\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 8.2586e-04 - val_loss: 1.3983\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0023 - val_loss: 1.2912\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 7.1107e-04 - val_loss: 1.2797\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 7.0086e-04 - val_loss: 1.3151\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 8.2740e-04 - val_loss: 1.3823\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0000e+00 - val_loss: 1.4489\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0031 - val_loss: 1.3920\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 9.7535e-05 - val_loss: 1.3297\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0021 - val_loss: 1.3664\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0000e+00 - val_loss: 2.8726\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0010 - val_loss: 2.9158\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 3.8119e-04 - val_loss: 1.9276\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 1s 68ms/step - loss: 0.0024 - val_loss: 1.3601\n",
            "WARNING:tensorflow:From <ipython-input-25-f9da150b1f54>:10: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-25-f9da150b1f54>:10: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.5454545454545454\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.7980 - val_loss: 0.7557\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.5295 - val_loss: 0.5750\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.5640 - val_loss: 0.6184\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3916 - val_loss: 0.6087\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.3103 - val_loss: 0.6080\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.2171 - val_loss: 1.0750\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.1494 - val_loss: 0.9863\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0954 - val_loss: 1.1074\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.1186 - val_loss: 1.0281\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0494 - val_loss: 1.4547\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0393 - val_loss: 1.4554\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0935 - val_loss: 1.9231\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.0231 - val_loss: 1.4759\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0215 - val_loss: 1.8577\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0159 - val_loss: 1.8629\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0132 - val_loss: 1.9780\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0089 - val_loss: 2.7306\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0050 - val_loss: 2.7365\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0069 - val_loss: 2.7506\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0142 - val_loss: 1.9972\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0173 - val_loss: 2.4044\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0068 - val_loss: 2.4123\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0063 - val_loss: 2.7514\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 7.4583e-04 - val_loss: 1.9724\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0014 - val_loss: 1.9674\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0089 - val_loss: 2.3361\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0012 - val_loss: 1.9255\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0042 - val_loss: 1.9525\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0054 - val_loss: 2.3647\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 2.4303e-04 - val_loss: 2.7545\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 9.7489e-04 - val_loss: 2.7697\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0038 - val_loss: 2.7462\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0061 - val_loss: 2.4131\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0038 - val_loss: 2.4194\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 8.3436e-04 - val_loss: 2.7335\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0023 - val_loss: 2.7472\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 8.6652e-04 - val_loss: 2.7648\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0023 - val_loss: 2.7491\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 3.5624e-04 - val_loss: 2.7433\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 8.0791e-04 - val_loss: 2.7421\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 2.9829e-04 - val_loss: 2.7446\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 9.7494e-04 - val_loss: 2.7771\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 6.5245e-04 - val_loss: 3.2016\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 5.5816e-04 - val_loss: 3.1871\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 5.4516e-04 - val_loss: 3.1873\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0015 - val_loss: 3.1753\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0046 - val_loss: 3.2039\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 6.9401e-04 - val_loss: 3.2097\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 6.8722e-04 - val_loss: 3.2021\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0066 - val_loss: 4.0664\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.6493506493506493\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.1624 - val_loss: 0.6510\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.6364 - val_loss: 0.7276\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.5848 - val_loss: 0.7521\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.5167 - val_loss: 0.6659\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.4733 - val_loss: 0.6438\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.3786 - val_loss: 0.6446\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.2588 - val_loss: 0.5979\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.2322 - val_loss: 0.6654\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.1447 - val_loss: 0.5689\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.1020 - val_loss: 1.0176\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0583 - val_loss: 1.4158\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0277 - val_loss: 1.3394\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.0477 - val_loss: 1.3665\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0096 - val_loss: 1.3215\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0138 - val_loss: 1.4222\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0150 - val_loss: 1.3172\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0166 - val_loss: 1.3577\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0166 - val_loss: 1.3239\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0111 - val_loss: 1.3562\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0146 - val_loss: 1.3188\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0020 - val_loss: 1.2950\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0059 - val_loss: 1.2931\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0093 - val_loss: 1.3714\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0030 - val_loss: 2.2320\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0047 - val_loss: 2.2007\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0050 - val_loss: 1.3127\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0033 - val_loss: 1.3432\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0059 - val_loss: 2.1921\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0077 - val_loss: 1.3625\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0064 - val_loss: 1.3295\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0045 - val_loss: 1.3773\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0045 - val_loss: 2.2052\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0031 - val_loss: 1.2991\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0054 - val_loss: 1.2795\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0094 - val_loss: 1.3849\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0023 - val_loss: 1.2620\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0025 - val_loss: 1.2493\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 7.1605e-04 - val_loss: 1.2807\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0030 - val_loss: 1.2548\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 6.8285e-04 - val_loss: 1.2602\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0010 - val_loss: 1.3220\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 4.5884e-04 - val_loss: 1.3020\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0012 - val_loss: 1.3123\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 2.3444e-04 - val_loss: 1.7580\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0017 - val_loss: 2.2090\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0016 - val_loss: 2.1863\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0000e+00 - val_loss: 1.8291\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 9.3458e-04 - val_loss: 1.7924\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 3.0420e-04 - val_loss: 2.2017\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0010 - val_loss: 2.2255\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.5844155844155844\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 6.8575 - val_loss: 10.4492\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 5.7060 - val_loss: 0.9092\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 2.2578 - val_loss: 0.5958\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 1.2309 - val_loss: 0.6153\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.8438 - val_loss: 0.5293\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.5073 - val_loss: 0.7359\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.4290 - val_loss: 0.5803\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.3519 - val_loss: 0.6283\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.2613 - val_loss: 0.5046\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.2512 - val_loss: 1.0701\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.1440 - val_loss: 0.4963\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.1272 - val_loss: 1.0553\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0905 - val_loss: 1.9844\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0549 - val_loss: 0.9897\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0442 - val_loss: 2.0215\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0284 - val_loss: 2.4256\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0233 - val_loss: 1.5970\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0150 - val_loss: 2.0366\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0112 - val_loss: 1.5665\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0125 - val_loss: 1.7278\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0122 - val_loss: 1.9299\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0113 - val_loss: 2.3496\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 1s 68ms/step - loss: 0.0125 - val_loss: 2.3555\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0033 - val_loss: 2.3799\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0072 - val_loss: 2.1328\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0058 - val_loss: 2.7139\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0049 - val_loss: 2.7345\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0028 - val_loss: 2.7257\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0037 - val_loss: 2.7391\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0032 - val_loss: 2.7357\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0071 - val_loss: 2.7227\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0041 - val_loss: 2.7348\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0041 - val_loss: 2.7480\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0018 - val_loss: 2.7130\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0030 - val_loss: 2.7491\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0029 - val_loss: 2.4401\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0015 - val_loss: 2.7238\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0045 - val_loss: 2.6855\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 7.5803e-04 - val_loss: 2.6859\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0013 - val_loss: 2.6525\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0053 - val_loss: 2.6613\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0021 - val_loss: 2.6897\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0029 - val_loss: 2.7084\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0034 - val_loss: 2.7921\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0011 - val_loss: 2.7702\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0030 - val_loss: 2.6820\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0017 - val_loss: 2.6726\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 7.6207e-04 - val_loss: 2.6717\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0020 - val_loss: 2.6775\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0000e+00 - val_loss: 2.6757\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.6753246753246753\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 7.5395 - val_loss: 4.1290\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 2.3948 - val_loss: 0.5882\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.7916 - val_loss: 0.6595\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.6443 - val_loss: 0.5461\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.6174 - val_loss: 0.5376\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.5465 - val_loss: 0.5875\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.5149 - val_loss: 0.5183\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.4505 - val_loss: 0.5200\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.3798 - val_loss: 0.5280\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.3306 - val_loss: 0.5243\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.2703 - val_loss: 0.4973\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.1876 - val_loss: 0.4911\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.1516 - val_loss: 0.5188\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.0923 - val_loss: 0.9509\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0834 - val_loss: 0.9873\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0640 - val_loss: 1.0201\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0651 - val_loss: 0.9493\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0549 - val_loss: 1.0462\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0368 - val_loss: 1.1147\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0364 - val_loss: 1.1717\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0297 - val_loss: 0.9999\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0198 - val_loss: 1.0861\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0118 - val_loss: 1.0317\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0172 - val_loss: 1.0399\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0141 - val_loss: 1.0727\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0131 - val_loss: 1.0670\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0082 - val_loss: 1.6386\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0129 - val_loss: 1.3003\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0105 - val_loss: 1.1961\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0051 - val_loss: 1.3166\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0074 - val_loss: 3.1027\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 1s 68ms/step - loss: 0.0040 - val_loss: 2.1939\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0059 - val_loss: 1.7691\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0016 - val_loss: 2.6213\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0036 - val_loss: 3.4798\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0022 - val_loss: 3.0025\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0022 - val_loss: 3.4215\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0058 - val_loss: 3.8784\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 5.4339e-04 - val_loss: 4.2514\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0078 - val_loss: 4.2587\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.0025 - val_loss: 4.2668\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0022 - val_loss: 4.2455\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 1s 68ms/step - loss: 0.0021 - val_loss: 3.8708\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0018 - val_loss: 3.8576\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0010 - val_loss: 4.2949\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0559 - val_loss: 4.3741\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0053 - val_loss: 4.6506\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 8.2006e-04 - val_loss: 4.6484\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0017 - val_loss: 3.9007\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0080 - val_loss: 2.6484\n",
            "Fold-------\n",
            "X_text_train shape: (308,) | y_train shape: (308,)\n",
            "X_text_test shape: (76,) | y_test shape: (76,)\n",
            "Accuracy: 0.6842105263157895\n",
            "Mean_Accuracy: 0.6277511961722487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3orxrigMkym",
        "colab_type": "text"
      },
      "source": [
        "# TFIDF embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPwxh1dO-1Jg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tfidf_features(text, training=True):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "    text - string\n",
        "    training - flag\n",
        "  Returns:\n",
        "    tfidf feature matrix\n",
        "  \"\"\"\n",
        "  if training:\n",
        "      x = tfidf.fit_transform(text)\n",
        "  else:\n",
        "      x = tfidf.transform(text)\n",
        "  x = x.astype('float32')\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkeJuGnfPK9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tfidf_features_best_plot(X_train, y_train, k=10):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "    X_train - datasets\n",
        "    y_train - labels\n",
        "    k - number of features to plot\n",
        "  Returns:\n",
        "    plots data\n",
        "  \"\"\" \n",
        "\n",
        "  chi2score = chi2(X_train, y_train)[0]\n",
        "  plt.figure(figsize=(15,10))\n",
        "  wscores = list(zip(tfidf.get_feature_names(), chi2score))\n",
        "  wchi2 = sorted(wscores, key=lambda x:x[1])\n",
        "  topchi2 = list(zip(*wchi2[-k:]))\n",
        "  x = range(len(topchi2[1]))\n",
        "  labels = topchi2[0]\n",
        "  plt.barh(x,topchi2[1], align='center', alpha=0.2)\n",
        "  plt.plot(topchi2[1], x, '-o', markersize=5, alpha=0.8)\n",
        "  plt.yticks(x, labels)\n",
        "  plt.xlabel('$\\chi^2$')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImHS-LpIYgtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tfidf_features_select(X_train, X_test, y_train, k=10):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "    X - data\n",
        "    y - labels\n",
        "    n - number of features to select\n",
        "  Returns:\n",
        "    dataset containing n best features\n",
        "  \"\"\"\n",
        "  # assume that a score higher than 3.5 indicates persuasivness in the content\n",
        "  y_train_binary = np.zeros(y_train.shape)\n",
        "  y_train_binary[y_train > 3.5] = 1.0 \n",
        "  \n",
        "  ch2 = SelectKBest(score_func=chi2, k=k)\n",
        "  X_train = ch2.fit_transform(X_train, y_train_binary)\n",
        "  X_test = ch2.transform(X_test)\n",
        "  return X_train, X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDoCVhlvX7r7",
        "colab_type": "text"
      },
      "source": [
        "## TFIDF_GB_Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R469OSxq_DBc",
        "colab_type": "code",
        "outputId": "c7ec0176-1e20-4157-8df0-943a29c82433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "kf = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "history = []\n",
        "for train_index, test_index in kf.split(X_text_pers, y_binary_pers):\n",
        "  X_text_train, X_text_test = X_text_pers[train_index], X_text_pers[test_index]\n",
        "  y_train, y_test = y_binary_pers[train_index], y_binary_pers[test_index]\n",
        "\n",
        "  tfidf = TfidfVectorizer(max_features=500, min_df=5, max_df=.7, ngram_range=(1,2), stop_words=stopwords.words('english'))\n",
        "  X_text_train_tfidf = tfidf_features(X_text_train).todense()\n",
        "  X_text_test_tfidf = tfidf_features(X_text_test, training=False).todense()\n",
        "\n",
        "  gb = get_gradient_boosting_classifier(500)\n",
        "  gb.fit(X_text_train_tfidf, y_train)\n",
        "  \n",
        "  y_pred = gb.predict(X_text_test_tfidf)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  \n",
        "  history.append(accuracy)\n",
        "  print(\"Fold-------\")\n",
        "  print(\"X_text_train shape: {} | y_train shape: {}\".format(X_text_train.shape, y_train.shape))\n",
        "  print(\"X_text_test shape: {} | y_test shape: {}\".format(X_text_test.shape, y_test.shape))\n",
        "\n",
        "  print(\"Accuracy: {}\".format(accuracy))\n",
        "print(\"Mean_Accuracy: {}\".format(np.mean(history)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.5454545454545454\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.6363636363636364\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.7142857142857143\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.6493506493506493\n",
            "Fold-------\n",
            "X_text_train shape: (308,) | y_train shape: (308,)\n",
            "X_text_test shape: (76,) | y_test shape: (76,)\n",
            "Accuracy: 0.631578947368421\n",
            "Mean_Accuracy: 0.6354066985645932\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7wcnyJS9wuG",
        "colab_type": "text"
      },
      "source": [
        "## TFIDF_RF_Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-QvcKFOHYw0",
        "colab_type": "code",
        "outputId": "aaf684bc-af97-42f3-fbc3-09e179d0e1e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "kf = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "history = []\n",
        "for train_index, test_index in kf.split(X_text_pers, y_binary_pers):\n",
        "  X_text_train, X_text_test = X_text_pers[train_index], X_text_pers[test_index]\n",
        "  y_train, y_test = y_binary_pers[train_index], y_binary_pers[test_index]\n",
        "  \n",
        "  tfidf = TfidfVectorizer(max_features=450, min_df=5, max_df=.7, ngram_range=(1,1), stop_words=stopwords.words('english'))\n",
        "  X_text_train_tfidf = tfidf_features(X_text_train).todense()\n",
        "  X_text_test_tfidf = tfidf_features(X_text_test, training=False).todense()\n",
        "  \n",
        "  # tfidf_features_best_plot(X_text_train_tfidf, y_train, 15)\n",
        "\n",
        "  rf = get_random_forest_classifier()\n",
        "  rf.fit(X_text_train_tfidf, y_train)\n",
        "  \n",
        "  y_pred = rf.predict(X_text_test_tfidf)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  \n",
        "  history.append(accuracy)\n",
        "  print(\"Fold-------\")\n",
        "  print(\"X_text_train shape: {} | y_train shape: {}\".format(X_text_train.shape, y_train.shape))\n",
        "  print(\"X_text_test shape: {} | y_test shape: {}\".format(X_text_test.shape, y_test.shape))\n",
        "\n",
        "  print(\"Accuracy: {}\".format(accuracy))\n",
        "print(\"Mean_Accuracy: {}\".format(np.mean(history)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.5974025974025974\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.6623376623376623\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.7402597402597403\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.7142857142857143\n",
            "Fold-------\n",
            "X_text_train shape: (308,) | y_train shape: (308,)\n",
            "X_text_test shape: (76,) | y_test shape: (76,)\n",
            "Accuracy: 0.7105263157894737\n",
            "Mean_Accuracy: 0.6849624060150376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPfLpwau5D3g",
        "colab_type": "text"
      },
      "source": [
        "## TFIDF_RF_Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxwtXeuWGwhM",
        "colab_type": "code",
        "outputId": "7e075d50-57d3-4798-c952-3823d0aa060e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "kf = KFold(n_splits=5, shuffle=False)\n",
        "history = []\n",
        "for train_index, test_index in kf.split(X_text, y_pers):\n",
        "  X_text_train, X_text_test = X_text[train_index], X_text[test_index]\n",
        "  y_train, y_test = y_pers[train_index], y_pers[test_index]\n",
        "\n",
        "  tfidf = TfidfVectorizer(max_features=500, min_df=5, max_df=.7, ngram_range=(1,1), stop_words=stopwords.words('english'))\n",
        "  X_text_train_tfidf = tfidf_features(X_text_train).todense()\n",
        "  X_text_test_tfidf = tfidf_features(X_text_test, training=False).todense()\n",
        "\n",
        "  rf = get_random_forest_regressor()\n",
        "  rf.fit(X_text_train_tfidf, y_train)\n",
        "  \n",
        "  y_pred = rf.predict(X_text_test_tfidf)\n",
        "  mae = mean_absolute_error(y_test, y_pred)\n",
        "  \n",
        "  history.append(mae)\n",
        "  print(\"Fold-------\")\n",
        "  print(\"X_text_train shape: {} | y_train shape: {}\".format(X_text_train.shape, y_train.shape))\n",
        "  print(\"X_text_test shape: {} | y_test shape: {}\".format(X_text_test.shape, y_test.shape))\n",
        "\n",
        "  print(\"Mean_Absolute_Error: {}\".format(mae))\n",
        "print(\"Mean_MAE: {}\".format(np.mean(history)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold-------\n",
            "X_text_train shape: (722,) | y_train shape: (722,)\n",
            "X_text_test shape: (181,) | y_test shape: (181,)\n",
            "Mean_Absolute_Error: 1.088195211786372\n",
            "Fold-------\n",
            "X_text_train shape: (722,) | y_train shape: (722,)\n",
            "X_text_test shape: (181,) | y_test shape: (181,)\n",
            "Mean_Absolute_Error: 0.981049723756906\n",
            "Fold-------\n",
            "X_text_train shape: (722,) | y_train shape: (722,)\n",
            "X_text_test shape: (181,) | y_test shape: (181,)\n",
            "Mean_Absolute_Error: 1.0929834254143649\n",
            "Fold-------\n",
            "X_text_train shape: (723,) | y_train shape: (723,)\n",
            "X_text_test shape: (180,) | y_test shape: (180,)\n",
            "Mean_Absolute_Error: 0.9606666666666668\n",
            "Fold-------\n",
            "X_text_train shape: (723,) | y_train shape: (723,)\n",
            "X_text_test shape: (180,) | y_test shape: (180,)\n",
            "Mean_Absolute_Error: 1.0360092592592594\n",
            "Mean_MAE: 1.0317808573767138\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SubOrCUA4hV1",
        "colab_type": "text"
      },
      "source": [
        "## TFIDF_Dense"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AbY-z-CDj0n",
        "colab_type": "code",
        "outputId": "8240a5cd-b269-43b6-b585-e4208750cbe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "kf = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "history = []\n",
        "for train_index, test_index in kf.split(X_text_pers, y_binary_pers):\n",
        "  X_text_train, X_text_test = X_text_pers[train_index], X_text_pers[test_index]\n",
        "  y_train, y_test = y_binary_pers[train_index], y_binary_pers[test_index]\n",
        "\n",
        "  tfidf = TfidfVectorizer(max_features=1000, min_df=5, max_df=.7, ngram_range=(1,1), stop_words=stopwords.words('english'))\n",
        "  X_text_train_tfidf = tfidf_features(X_text_train).todense()\n",
        "  X_text_test_tfidf = tfidf_features(X_text_test, training=False).todense()\n",
        "\n",
        "  dense = get_dense_classifier(X_text_train_tfidf.shape[1])\n",
        "  dense.fit(X_text_train_tfidf, y_train, epochs=100, batch_size=5, validation_split=.1, verbose=None)\n",
        "  \n",
        "  y_pred = dense.predict_classes(X_text_test_tfidf)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  \n",
        "  history.append(accuracy)\n",
        "  print(\"Fold-------\")\n",
        "  print(\"X_text_train shape: {} | y_train shape: {}\".format(X_text_train.shape, y_train.shape))\n",
        "  print(\"X_text_test shape: {} | y_test shape: {}\".format(X_text_test.shape, y_test.shape))\n",
        "\n",
        "  print(\"Accuracy: {}\".format(accuracy))\n",
        "print(\"Mean_Accuracy: {}\".format(np.mean(history)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.6103896103896104\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.6103896103896104\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.5454545454545454\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.6753246753246753\n",
            "Fold-------\n",
            "X_text_train shape: (308,) | y_train shape: (308,)\n",
            "X_text_test shape: (76,) | y_test shape: (76,)\n",
            "Accuracy: 0.6710526315789473\n",
            "Mean_Accuracy: 0.6225222146274778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPJaaIHtvOOl",
        "colab_type": "text"
      },
      "source": [
        "# Audio_Proccessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk12mzReSc2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_audio_features(dataset):\n",
        "  \"\"\"\n",
        "  Arguments\n",
        "    dataset - array of time series per 10ms of audio ([[19, 193, 312 3,123 12, ....., 312312], [19, 193, 312 3,123 12, ....., 312312], [19, 193, 312 3,123 12, ....., 312312]])\n",
        "  Returns\n",
        "    (mean, std, max, min, skew) along time series for eatch data point\n",
        "  \"\"\"\n",
        "  data_features = []\n",
        "  for data in dataset:\n",
        "    mean = np.nan_to_num(np.mean(data, axis=0))\n",
        "    median = np.nan_to_num(np.median(data, axis=0))\n",
        "    minimum = np.nan_to_num(np.min(data, axis=0))\n",
        "    maximum = np.nan_to_num(np.max(data, axis=0))\n",
        "    std = np.nan_to_num(np.std(data, axis=0))\n",
        "\n",
        "    # min_max_range = maximum - minimum\n",
        "    skew = np.nan_to_num(3 * (mean - median) / std)\n",
        "\n",
        "    data_features.append([mean, median, std, minimum, maximum, skew])\n",
        "  return np.array(data_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0PzXZ_qvSFl",
        "colab_type": "code",
        "outputId": "b7b77a34-cb6f-4ede-8790-21f0877dd969",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_audio_feat = extract_audio_features(X_audio)\n",
        "X_audio_feat = X_audio_feat.reshape(903, -1).astype(np.float32)\n",
        "X_audio_feat_pers = X_audio_feat[pers_relevant_i]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:193: RuntimeWarning: invalid value encountered in subtract\n",
            "  x = asanyarray(arr - arrmean)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: RuntimeWarning: overflow encountered in multiply\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7WKzdQHYH68",
        "colab_type": "text"
      },
      "source": [
        "## Audio_GB_Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXzb1ReWgN8a",
        "colab_type": "code",
        "outputId": "7c5f8749-9aca-4737-e5d5-daf4243bcb95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "kf = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "history = []\n",
        "for train_index, test_index in kf.split(X_audio_feat_pers, y_binary_pers):\n",
        "  X_audio_train, X_audio_test =  X_audio_feat_pers[train_index], X_audio_feat_pers[test_index]\n",
        "  y_train, y_test = y_binary_pers[train_index], y_binary_pers[test_index]\n",
        "\n",
        "  gb = get_gradient_boosting_classifier()\n",
        "  gb.fit(X_audio_train, y_train)\n",
        "  \n",
        "  y_pred = gb.predict(X_audio_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  \n",
        "  history.append(accuracy)\n",
        "  print(\"Fold-------\")\n",
        "  print(\"X_text_train shape: {} | y_train shape: {}\".format(X_audio_train.shape, y_train.shape))\n",
        "  print(\"X_text_test shape: {} | y_test shape: {}\".format(X_audio_test.shape, y_test.shape))\n",
        "\n",
        "  print(\"Accuracy: {}\".format(accuracy))\n",
        "print(\"Mean_Accuracy: {}\".format(np.mean(history)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold-------\n",
            "X_text_train shape: (307, 258) | y_train shape: (307,)\n",
            "X_text_test shape: (77, 258) | y_test shape: (77,)\n",
            "Accuracy: 0.5844155844155844\n",
            "Fold-------\n",
            "X_text_train shape: (307, 258) | y_train shape: (307,)\n",
            "X_text_test shape: (77, 258) | y_test shape: (77,)\n",
            "Accuracy: 0.5844155844155844\n",
            "Fold-------\n",
            "X_text_train shape: (307, 258) | y_train shape: (307,)\n",
            "X_text_test shape: (77, 258) | y_test shape: (77,)\n",
            "Accuracy: 0.6883116883116883\n",
            "Fold-------\n",
            "X_text_train shape: (307, 258) | y_train shape: (307,)\n",
            "X_text_test shape: (77, 258) | y_test shape: (77,)\n",
            "Accuracy: 0.5584415584415584\n",
            "Fold-------\n",
            "X_text_train shape: (308, 258) | y_train shape: (308,)\n",
            "X_text_test shape: (76, 258) | y_test shape: (76,)\n",
            "Accuracy: 0.631578947368421\n",
            "Mean_Accuracy: 0.6094326725905674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plryddazgND5",
        "colab_type": "text"
      },
      "source": [
        "## Audio_RF_Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doTDnugJBU9v",
        "colab_type": "code",
        "outputId": "771e29a0-aea0-4320-e29a-e3b1a8abe210",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "kf = KFold(n_splits=5, shuffle=False)\n",
        "history = []\n",
        "for train_index, test_index in kf.split(X_audio_feat_pers, y_binary_pers):\n",
        "  X_audio_train, X_audio_test =  X_audio_feat_pers[train_index], X_audio_feat_pers[test_index]\n",
        "  y_train, y_test = y_binary_pers[train_index], y_binary_pers[test_index]\n",
        "\n",
        "  rf = get_random_forest_classifier()\n",
        "  rf.fit(X_audio_train, y_train)\n",
        "  \n",
        "  y_pred = rf.predict(X_audio_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  \n",
        "  history.append(accuracy)\n",
        "  print(\"Fold-------\")\n",
        "  print(\"X_text_train shape: {} | y_train shape: {}\".format(X_audio_train.shape, y_train.shape))\n",
        "  print(\"X_text_test shape: {} | y_test shape: {}\".format(X_audio_test.shape, y_test.shape))\n",
        "\n",
        "  print(\"Mean_Absolute_Error: {}\".format(accuracy))\n",
        "print(\"Mean_MAE: {}\".format(np.mean(history)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold-------\n",
            "X_text_train shape: (307, 301) | y_train shape: (307,)\n",
            "X_text_test shape: (77, 301) | y_test shape: (77,)\n",
            "Mean_Absolute_Error: 0.6883116883116883\n",
            "Fold-------\n",
            "X_text_train shape: (307, 301) | y_train shape: (307,)\n",
            "X_text_test shape: (77, 301) | y_test shape: (77,)\n",
            "Mean_Absolute_Error: 0.5844155844155844\n",
            "Fold-------\n",
            "X_text_train shape: (307, 301) | y_train shape: (307,)\n",
            "X_text_test shape: (77, 301) | y_test shape: (77,)\n",
            "Mean_Absolute_Error: 0.6753246753246753\n",
            "Fold-------\n",
            "X_text_train shape: (307, 301) | y_train shape: (307,)\n",
            "X_text_test shape: (77, 301) | y_test shape: (77,)\n",
            "Mean_Absolute_Error: 0.6493506493506493\n",
            "Fold-------\n",
            "X_text_train shape: (308, 301) | y_train shape: (308,)\n",
            "X_text_test shape: (76, 301) | y_test shape: (76,)\n",
            "Mean_Absolute_Error: 0.6842105263157895\n",
            "Mean_MAE: 0.6563226247436773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7Mz9Isn6C6u",
        "colab_type": "text"
      },
      "source": [
        "## Audio_RF_Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CkMLoocJ2u9",
        "colab_type": "code",
        "outputId": "05643b34-07ca-4f38-d749-4757f05211ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "kf = KFold(n_splits=5, shuffle=False)\n",
        "history = []\n",
        "for train_index, test_index in kf.split(X_text, y_pers):\n",
        "  X_audio_train, X_audio_test =  X_audio_feat[train_index], X_audio_feat[test_index]\n",
        "  y_train, y_test = y_pers[train_index], y_pers[test_index]\n",
        "\n",
        "  rf = get_random_forest_regressor()\n",
        "  rf.fit(X_audio_train, y_train)\n",
        "  \n",
        "  y_pred = rf.predict(X_audio_test)\n",
        "  mae = mean_absolute_error(y_test, y_pred)\n",
        "  \n",
        "  history.append(mae)\n",
        "  print(\"Fold-------\")\n",
        "  print(\"X_text_train shape: {} | y_train shape: {}\".format(X_text_train.shape, y_train.shape))\n",
        "  print(\"X_text_test shape: {} | y_test shape: {}\".format(X_text_test.shape, y_test.shape))\n",
        "\n",
        "  print(\"Mean_Absolute_Error: {}\".format(mae))\n",
        "print(\"Mean_MAE: {}\".format(np.mean(history)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold-------\n",
            "X_text_train shape: (723,) | y_train shape: (722,)\n",
            "X_text_test shape: (180,) | y_test shape: (181,)\n",
            "Mean_Absolute_Error: 1.0426887661141804\n",
            "Fold-------\n",
            "X_text_train shape: (723,) | y_train shape: (722,)\n",
            "X_text_test shape: (180,) | y_test shape: (181,)\n",
            "Mean_Absolute_Error: 1.0848176795580111\n",
            "Fold-------\n",
            "X_text_train shape: (723,) | y_train shape: (722,)\n",
            "X_text_test shape: (180,) | y_test shape: (181,)\n",
            "Mean_Absolute_Error: 1.102449355432781\n",
            "Fold-------\n",
            "X_text_train shape: (723,) | y_train shape: (723,)\n",
            "X_text_test shape: (180,) | y_test shape: (180,)\n",
            "Mean_Absolute_Error: 0.9974629629629629\n",
            "Fold-------\n",
            "X_text_train shape: (723,) | y_train shape: (723,)\n",
            "X_text_test shape: (180,) | y_test shape: (180,)\n",
            "Mean_Absolute_Error: 1.0584018518518516\n",
            "Mean_MAE: 1.0571641231839575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSlS2CiOLwJ1",
        "colab_type": "text"
      },
      "source": [
        "## Audio_Dense"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjarsSJ6L0_4",
        "colab_type": "code",
        "outputId": "8c7a8ff8-1c36-4f64-a44a-cd7e054073b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "kf = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "history = []\n",
        "for train_index, test_index in kf.split(X_audio_feat_pers, y_binary_pers):\n",
        "  X_audio_train, X_audio_test =  X_audio_feat_pers[train_index], X_audio_feat_pers[test_index]\n",
        "  y_train, y_test = y_binary_pers[train_index], y_binary_pers[test_index]\n",
        "\n",
        "  dense = get_dense_classifier(X_audio_train.shape[1])\n",
        "  dense.fit(X_audio_train, y_train, epochs=100, batch_size=10, validation_split=.1, verbose=None)\n",
        "  \n",
        "  y_pred = dense.predict_classes(X_audio_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  \n",
        "  history.append(accuracy)\n",
        "  print(\"Fold-------\")\n",
        "  print(\"X_text_train shape: {} | y_train shape: {}\".format(X_audio_train.shape, y_train.shape))\n",
        "  print(\"X_text_test shape: {} | y_test shape: {}\".format(X_audio_test.shape, y_test.shape))\n",
        "\n",
        "  print(\"Mean_Absolute_Error: {}\".format(accuracy))\n",
        "print(\"Mean_MAE: {}\".format(np.mean(history)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold-------\n",
            "X_text_train shape: (307, 258) | y_train shape: (307,)\n",
            "X_text_test shape: (77, 258) | y_test shape: (77,)\n",
            "Mean_Absolute_Error: 0.5194805194805194\n",
            "Fold-------\n",
            "X_text_train shape: (307, 258) | y_train shape: (307,)\n",
            "X_text_test shape: (77, 258) | y_test shape: (77,)\n",
            "Mean_Absolute_Error: 0.4935064935064935\n",
            "Fold-------\n",
            "X_text_train shape: (307, 258) | y_train shape: (307,)\n",
            "X_text_test shape: (77, 258) | y_test shape: (77,)\n",
            "Mean_Absolute_Error: 0.5064935064935064\n",
            "Fold-------\n",
            "X_text_train shape: (307, 258) | y_train shape: (307,)\n",
            "X_text_test shape: (77, 258) | y_test shape: (77,)\n",
            "Mean_Absolute_Error: 0.4805194805194805\n",
            "Fold-------\n",
            "X_text_train shape: (308, 258) | y_train shape: (308,)\n",
            "X_text_test shape: (76, 258) | y_test shape: (76,)\n",
            "Mean_Absolute_Error: 0.5657894736842105\n",
            "Mean_MAE: 0.513157894736842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2atKpte7UxH5",
        "colab_type": "text"
      },
      "source": [
        "# Feature fusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnedf5AkdNeW",
        "colab_type": "text"
      },
      "source": [
        "## Early"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtWWLRuuYeWP",
        "colab_type": "text"
      },
      "source": [
        "### GB_Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghDk-n2-KuFS",
        "colab_type": "code",
        "outputId": "e8869b08-1137-4a87-d97b-61364d6d7c76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "kf = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "history = []\n",
        "for train_index, test_index in kf.split(X_text_pers, y_binary_pers):\n",
        "  y_train, y_test = y_binary_pers[train_index], y_binary_pers[test_index]\n",
        "  X_text_train, X_text_test = X_text_pers[train_index], X_text_pers[test_index]\n",
        "  X_audio_train, X_audio_test = X_audio_feat_pers[train_index], X_audio_feat_pers[test_index]\n",
        "\n",
        "  tfidf = TfidfVectorizer(max_features=100, min_df=5, max_df=.9, stop_words=stopwords.words('english'))\n",
        "  X_text_train_feat = tfidf_features(X_text_train).todense()\n",
        "  X_text_test_feat = tfidf_features(X_text_test, training=False).todense()\n",
        "\n",
        "  # Fuse features\n",
        "  X_train = np.hstack((X_text_train_feat, X_audio_train))\n",
        "  X_test = np.hstack((X_text_test_feat, X_audio_test))\n",
        "\n",
        "  rf_model = get_gradient_boosting_classifier()\n",
        "  rf_model.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = rf_model.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  history.append(accuracy)\n",
        "\n",
        "  print(\"Fold-------\")\n",
        "  print(\"X_text_train shape: {} | y_train shape: {}\".format(X_text_train.shape, y_train.shape))\n",
        "  print(\"X_text_test shape: {} | y_test shape: {}\".format(X_text_test.shape, y_test.shape))\n",
        "  print(\"Accuracy: {}\".format(accuracy))\n",
        "print(\"Mean_Accuracy: {}\".format(np.mean(history)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.6883116883116883\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.6233766233766234\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.7012987012987013\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.6883116883116883\n",
            "Fold-------\n",
            "X_text_train shape: (308,) | y_train shape: (308,)\n",
            "X_text_test shape: (76,) | y_test shape: (76,)\n",
            "Accuracy: 0.6710526315789473\n",
            "Mean_Accuracy: 0.6744702665755298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWq6EyolkMJQ",
        "colab_type": "text"
      },
      "source": [
        "### RF_Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWGPvGU4kLiW",
        "colab_type": "code",
        "outputId": "5420cc11-431e-465f-d74d-16dc16ec13d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "kf = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "history = []\n",
        "for train_index, test_index in kf.split(X_text_pers, y_binary_pers):\n",
        "  y_train, y_test = y_binary_pers[train_index], y_binary_pers[test_index]\n",
        "  X_text_train, X_text_test = X_text_pers[train_index], X_text_pers[test_index]\n",
        "  X_audio_train, X_audio_test = X_audio_feat_pers[train_index], X_audio_feat_pers[test_index]\n",
        "\n",
        "  tfidf = TfidfVectorizer(max_features=100, min_df=5, max_df=.9, stop_words=stopwords.words('english'))\n",
        "  X_text_train_feat = tfidf_features(X_text_train).todense()\n",
        "  X_text_test_feat = tfidf_features(X_text_test, training=False).todense()\n",
        "\n",
        "  # Fuse features\n",
        "  X_train = np.hstack((X_text_train_feat, X_audio_train))\n",
        "  X_test = np.hstack((X_text_test_feat, X_audio_test))\n",
        "\n",
        "  rf_model = get_random_forest_classifier()\n",
        "  rf_model.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = rf_model.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  history.append(accuracy)\n",
        "\n",
        "  print(\"Fold-------\")\n",
        "  print(\"X_text_train shape: {} | y_train shape: {}\".format(X_text_train.shape, y_train.shape))\n",
        "  print(\"X_text_test shape: {} | y_test shape: {}\".format(X_text_test.shape, y_test.shape))\n",
        "  print(\"Accuracy: {}\".format(accuracy))\n",
        "print(\"Mean_Accuracy: {}\".format(np.mean(history)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.6493506493506493\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.6493506493506493\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.7142857142857143\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.6623376623376623\n",
            "Fold-------\n",
            "X_text_train shape: (308,) | y_train shape: (308,)\n",
            "X_text_test shape: (76,) | y_test shape: (76,)\n",
            "Accuracy: 0.6578947368421053\n",
            "Mean_Accuracy: 0.6666438824333561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suzbf0TSx6d1",
        "colab_type": "text"
      },
      "source": [
        "## Dense_Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqJhyn3Hx5v9",
        "colab_type": "code",
        "outputId": "124bf96c-3e44-4329-bd2a-c2e3629c6bfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "kf = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "history = []\n",
        "for train_index, test_index in kf.split(X_text_pers, y_binary_pers):\n",
        "  y_train, y_test = y_binary_pers[train_index], y_binary_pers[test_index]\n",
        "  X_text_train, X_text_test = X_text_pers[train_index], X_text_pers[test_index]\n",
        "  X_audio_train, X_audio_test = X_audio_feat_pers[train_index], X_audio_feat_pers[test_index]\n",
        "\n",
        "  tfidf = TfidfVectorizer(max_features=100, min_df=5, max_df=.9, stop_words=stopwords.words('english'))\n",
        "  X_text_train_feat = tfidf_features(X_text_train).todense()\n",
        "  X_text_test_feat = tfidf_features(X_text_test, training=False).todense()\n",
        "\n",
        "  # Fuse features\n",
        "  X_train = np.hstack((X_text_train_feat, X_audio_train))\n",
        "  X_test = np.hstack((X_text_test_feat, X_audio_test))\n",
        "\n",
        "  dense = get_dense_classifier(X_train.shape[1])\n",
        "  dense.fit(X_train, y_train, epochs=100, batch_size=10, validation_split=.1, verbose=None)\n",
        "\n",
        "  y_pred = dense.predict_classes(X_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  history.append(accuracy)\n",
        "\n",
        "  print(\"Fold-------\")\n",
        "  print(\"X_text_train shape: {} | y_train shape: {}\".format(X_text_train.shape, y_train.shape))\n",
        "  print(\"X_text_test shape: {} | y_test shape: {}\".format(X_text_test.shape, y_test.shape))\n",
        "  print(\"Accuracy: {}\".format(accuracy))\n",
        "print(\"Mean_Accuracy: {}\".format(np.mean(history)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.5194805194805194\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.5064935064935064\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.5064935064935064\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy: 0.5064935064935064\n",
            "Fold-------\n",
            "X_text_train shape: (308,) | y_train shape: (308,)\n",
            "X_text_test shape: (76,) | y_test shape: (76,)\n",
            "Accuracy: 0.5921052631578947\n",
            "Mean_Accuracy: 0.5262132604237867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_rs27mhkJSn",
        "colab_type": "text"
      },
      "source": [
        "### RF_Rgression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf_iYocOdPN7",
        "colab_type": "code",
        "outputId": "e3fac21c-213d-4a4a-8ea2-5db8fda0e3f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "kf = KFold(n_splits=5, shuffle=False)\n",
        "history = []\n",
        "for train_index, test_index in kf.split(X_text, y_pers):\n",
        "  y_train, y_test = y_pers[train_index], y_pers[test_index]\n",
        "  X_text_train, X_text_test = X_text[train_index], X_text[test_index]\n",
        "  X_audio_train, X_audio_test = X_audio_feat[train_index], X_audio_feat[test_index]\n",
        "\n",
        "  tfidf = TfidfVectorizer(max_features=100, min_df=5, max_df=0.9, stop_words=stopwords.words('english'))\n",
        "  X_text_train_feat = tfidf_features(X_text_train).todense()\n",
        "  X_text_test_feat = tfidf_features(X_text_test, training=False).todense()\n",
        "\n",
        "  # Fuse features\n",
        "  X_train = np.hstack((X_text_train_feat, X_audio_train))\n",
        "  X_test = np.hstack((X_text_test_feat, X_audio_test))\n",
        "\n",
        "  rf_model = get_random_forest_regressor()\n",
        "  rf_model.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = rf_model.predict(X_test)\n",
        "  mae = mean_absolute_error(y_test, y_pred)\n",
        "  history.append(mae)\n",
        "  print(\"Fold-------\")\n",
        "  print(\"X_text_train shape: {} | y_train shape: {}\".format(X_text_train.shape, y_train.shape))\n",
        "  print(\"X_text_test shape: {} | y_test shape: {}\".format(X_text_test.shape, y_test.shape))\n",
        "  print(\"Mean_Absolute_Error: {}\".format(mae))\n",
        "print(\"Mean_MAE: {}\".format(np.mean(history)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold-------\n",
            "X_text_train shape: (722,) | y_train shape: (722,)\n",
            "X_text_test shape: (181,) | y_test shape: (181,)\n",
            "Mean_Absolute_Error: 1.034622467771639\n",
            "Fold-------\n",
            "X_text_train shape: (722,) | y_train shape: (722,)\n",
            "X_text_test shape: (181,) | y_test shape: (181,)\n",
            "Mean_Absolute_Error: 1.0494843462246777\n",
            "Fold-------\n",
            "X_text_train shape: (722,) | y_train shape: (722,)\n",
            "X_text_test shape: (181,) | y_test shape: (181,)\n",
            "Mean_Absolute_Error: 1.0779097605893186\n",
            "Fold-------\n",
            "X_text_train shape: (723,) | y_train shape: (723,)\n",
            "X_text_test shape: (180,) | y_test shape: (180,)\n",
            "Mean_Absolute_Error: 0.9836851851851852\n",
            "Fold-------\n",
            "X_text_train shape: (723,) | y_train shape: (723,)\n",
            "X_text_test shape: (180,) | y_test shape: (180,)\n",
            "Mean_Absolute_Error: 1.038824074074074\n",
            "Mean_MAE: 1.0369051667689788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl2BsezGc6lX",
        "colab_type": "text"
      },
      "source": [
        "## Late"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eEBWTfDqDbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_proba_to_pred(y_1, y_2):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "    y_1 - 1st model probabilities for classes\n",
        "    y_2 - 2nd model probabilities for classes\n",
        "  Returns:\n",
        "    0, 1 classes according to probabilities\n",
        "  \"\"\"\n",
        "  y_merged = (y_1 + y_2) / 2\n",
        "  return np.argmax(y_merged, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATjlH4QEYjyN",
        "colab_type": "text"
      },
      "source": [
        "### GB_Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHKjjmhcLhWG",
        "colab_type": "code",
        "outputId": "2177bf9e-5501-42ca-fa04-aeee8f3186d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "kf = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "history = []\n",
        "for train_index, test_index in kf.split(X_text_pers, y_binary_pers):\n",
        "  y_train, y_test = y_binary_pers[train_index], y_binary_pers[test_index]\n",
        "  X_text_train, X_text_test = X_text_pers[train_index], X_text_pers[test_index]\n",
        "  X_audio_train, X_audio_test = X_audio_feat_pers[train_index], X_audio_feat_pers[test_index]\n",
        "\n",
        "  tfidf = TfidfVectorizer(max_features=100, min_df=5, max_df=0.9, stop_words=stopwords.words('english'))\n",
        "  X_text_train_feat = tfidf_features(X_text_train).todense()\n",
        "  X_text_test_feat = tfidf_features(X_text_test, training=False).todense()\n",
        "\n",
        "  gb_text = get_gradient_boosting_classifier()\n",
        "  gb_audio = get_gradient_boosting_classifier()\n",
        "\n",
        "  gb_text.fit(X_text_train_feat, y_train)\n",
        "  gb_audio.fit(X_audio_train, y_train)\n",
        "\n",
        "  y_prob_text = gb_text.predict_proba(X_text_test_feat)\n",
        "  y_prob_audio = gb_audio.predict_proba(X_audio_test)\n",
        "  y_pred_text_audio = compute_proba_to_pred(y_prob_text, y_prob_audio)\n",
        "\n",
        "  accuracy = accuracy_score(y_test, y_pred_text_audio)\n",
        "  history.append(accuracy)\n",
        "\n",
        "  print(\"Fold-------\")\n",
        "  print(\"X_text_train shape: {} | y_train shape: {}\".format(X_text_train.shape, y_train.shape))\n",
        "  print(\"X_text_test shape: {} | y_test shape: {}\".format(X_text_test.shape, y_test.shape))\n",
        "  print(\"Accuracy text and audio: {}\".format(accuracy))\n",
        "print(\"Mean_Accuracy: {}\".format(np.mean(history)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy text and audio: 0.5194805194805194\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy text and audio: 0.6233766233766234\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy text and audio: 0.6883116883116883\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy text and audio: 0.6363636363636364\n",
            "Fold-------\n",
            "X_text_train shape: (308,) | y_train shape: (308,)\n",
            "X_text_test shape: (76,) | y_test shape: (76,)\n",
            "Accuracy text and audio: 0.6578947368421053\n",
            "Mean_Accuracy: 0.6250854408749145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBjOgMChpjik",
        "colab_type": "text"
      },
      "source": [
        "### RF_Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqwyoxruplS_",
        "colab_type": "code",
        "outputId": "1984a11c-688f-48eb-966a-73368eba67be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "kf = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "history = []\n",
        "for train_index, test_index in kf.split(X_text_pers, y_binary_pers):\n",
        "  y_train, y_test = y_binary_pers[train_index], y_binary_pers[test_index]\n",
        "  X_text_train, X_text_test = X_text_pers[train_index], X_text_pers[test_index]\n",
        "  X_audio_train, X_audio_test = X_audio_feat_pers[train_index], X_audio_feat_pers[test_index]\n",
        "\n",
        "  tfidf = TfidfVectorizer(max_features=500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
        "  X_text_train_feat = tfidf_features(X_text_train).todense()\n",
        "  X_text_test_feat = tfidf_features(X_text_test, training=False).todense()\n",
        "\n",
        "  rf_text = get_random_forest_classifier()\n",
        "  rf_audio = get_random_forest_classifier()\n",
        "\n",
        "  rf_text.fit(X_text_train_feat, y_train)\n",
        "  rf_audio.fit(X_audio_train, y_train)\n",
        "\n",
        "  y_prob_text = rf_text.predict_proba(X_text_test_feat)\n",
        "  y_prob_audio = rf_audio.predict_proba(X_audio_test)\n",
        "  y_pred_text_audio = compute_proba_to_pred(y_prob_text, y_prob_audio)\n",
        "\n",
        "  accuracy = accuracy_score(y_test, y_pred_text_audio)\n",
        "  history.append(accuracy)\n",
        "\n",
        "  print(\"Fold-------\")\n",
        "  print(\"X_text_train shape: {} | y_train shape: {}\".format(X_text_train.shape, y_train.shape))\n",
        "  print(\"X_text_test shape: {} | y_test shape: {}\".format(X_text_test.shape, y_test.shape))\n",
        "  print(\"Accuracy text and audio: {}\".format(accuracy))\n",
        "print(\"Mean_Accuracy: {}\".format(np.mean(history)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy text and audio: 0.6623376623376623\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy text and audio: 0.6883116883116883\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy text and audio: 0.7532467532467533\n",
            "Fold-------\n",
            "X_text_train shape: (307,) | y_train shape: (307,)\n",
            "X_text_test shape: (77,) | y_test shape: (77,)\n",
            "Accuracy text and audio: 0.7402597402597403\n",
            "Fold-------\n",
            "X_text_train shape: (308,) | y_train shape: (308,)\n",
            "X_text_test shape: (76,) | y_test shape: (76,)\n",
            "Accuracy text and audio: 0.7368421052631579\n",
            "Mean_Accuracy: 0.7161995898838004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqhFTfOacb9V",
        "colab_type": "text"
      },
      "source": [
        "### RF_Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDVpAAswU00w",
        "colab_type": "code",
        "outputId": "8c089052-b2c9-41d3-9a08-4a0209599eb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "kf = KFold(n_splits=5, shuffle=False)\n",
        "history = []\n",
        "for train_index, test_index in kf.split(X_text, y_pers):\n",
        "  y_train, y_test = y_pers[train_index], y_pers[test_index]\n",
        "  X_text_train, X_text_test = X_text[train_index], X_text[test_index]\n",
        "  X_audio_train, X_audio_test = X_audio_feat[train_index], X_audio_feat[test_index]\n",
        "\n",
        "  tfidf = TfidfVectorizer(max_features=100, min_df=5, max_df=0.9, stop_words=stopwords.words('english'))\n",
        "  X_text_train_feat = tfidf_features(X_text_train).todense()\n",
        "  X_text_test_feat = tfidf_features(X_text_test, training=False).todense()\n",
        "\n",
        "  rf_text = get_random_forest_regressor()\n",
        "  rf_audio = get_random_forest_regressor()\n",
        "\n",
        "  rf_text.fit(X_text_train_feat, y_train)\n",
        "  rf_audio.fit(X_audio_train, y_train)\n",
        "\n",
        "  y_pred_text = rf_text.predict(X_text_test_feat)\n",
        "  y_pred_audio = rf_audio.predict(X_audio_test)\n",
        "  y_pred_text_audio = np.mean(np.vstack((y_pred_text, y_pred_audio)), axis=0)\n",
        "\n",
        "  mae = mean_absolute_error(y_test, y_pred_text_audio)\n",
        "  history.append(mae)\n",
        "  print(\"Fold-------\")\n",
        "  print(\"X_text_train shape: {} | y_train shape: {}\".format(X_text_train.shape, y_train.shape))\n",
        "  print(\"X_text_test shape: {} | y_test shape: {}\".format(X_text_test.shape, y_test.shape))\n",
        "\n",
        "  print(\"MAE text: {}\".format(mean_absolute_error(y_test, y_pred_text)))\n",
        "  print(\"MAE audio: {}\".format(mean_absolute_error(y_test, y_pred_audio)))\n",
        "  print(\"MAE text and audio: {}\".format(mae))\n",
        "print(\"Mean_MAE: {}\".format(np.mean(history)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold-------\n",
            "X_text_train shape: (722,) | y_train shape: (722,)\n",
            "X_text_test shape: (181,) | y_test shape: (181,)\n",
            "MAE text: 1.074852670349908\n",
            "MAE audio: 1.0426887661141804\n",
            "MAE text and audio: 1.0438259668508287\n",
            "Fold-------\n",
            "X_text_train shape: (722,) | y_train shape: (722,)\n",
            "X_text_test shape: (181,) | y_test shape: (181,)\n",
            "MAE text: 1.007255985267035\n",
            "MAE audio: 1.0848176795580111\n",
            "MAE text and audio: 1.017841620626151\n",
            "Fold-------\n",
            "X_text_train shape: (722,) | y_train shape: (722,)\n",
            "X_text_test shape: (181,) | y_test shape: (181,)\n",
            "MAE text: 1.0897237569060771\n",
            "MAE audio: 1.102449355432781\n",
            "MAE text and audio: 1.0773848987108656\n",
            "Fold-------\n",
            "X_text_train shape: (723,) | y_train shape: (723,)\n",
            "X_text_test shape: (180,) | y_test shape: (180,)\n",
            "MAE text: 1.0076851851851854\n",
            "MAE audio: 0.9974629629629629\n",
            "MAE text and audio: 0.9832759259259259\n",
            "Fold-------\n",
            "X_text_train shape: (723,) | y_train shape: (723,)\n",
            "X_text_test shape: (180,) | y_test shape: (180,)\n",
            "MAE text: 1.0754074074074074\n",
            "MAE audio: 1.0584018518518516\n",
            "MAE text and audio: 1.054349074074074\n",
            "Mean_MAE: 1.035335497237569\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}